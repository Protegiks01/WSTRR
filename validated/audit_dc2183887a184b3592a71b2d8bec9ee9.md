# Audit Report

## Title
Missing Monotonicity Validation Allows DKG Round Regression via Replay Attacks

## Summary
The WSTS protocol state machines lack monotonicity validation for DKG round IDs, allowing both coordinators and signers to accept and process `DkgBegin` messages with `dkg_id` values less than their current round. This enables protocol participants to regress to previous DKG rounds when old legitimately-signed messages are replayed, violating the state machine invariant that round IDs should progress monotonically.

## Finding Description

This vulnerability exists across three interconnected components in the production codebase:

**Signer State Machine Vulnerability:**

The signer's `dkg_begin()` function unconditionally accepts any `dkg_id` value without validation and immediately calls `reset()` to regress to that round. [1](#0-0) 

The `reset()` function directly overwrites `self.dkg_id` with any provided value, including values lower than the current round, with no monotonicity check. [2](#0-1) 

**FROST Coordinator Vulnerability:**

The FROST coordinator only checks for equality (`self.current_dkg_id == dkg_begin.dkg_id`) to detect duplicate messages, but does NOT reject messages where `dkg_begin.dkg_id < self.current_dkg_id`. When the equality check fails (meaning the IDs differ), it proceeds to call `start_dkg_round()` with the potentially older ID. [3](#0-2) 

The `start_dkg_round()` function unconditionally sets `self.current_dkg_id` to whatever value is provided via the `dkg_id` parameter, enabling regression to earlier rounds. [4](#0-3) 

**FIRE Coordinator Vulnerability:**

The FIRE coordinator implementation exhibits the identical vulnerability pattern, with the same equality-only check. [5](#0-4) 

The FIRE coordinator's `start_dkg_round()` also unconditionally sets `self.current_dkg_id` to any provided value. [6](#0-5) 

**Why Existing Protections Are Insufficient:**

While `DkgBegin` messages are signed by the coordinator and verified by recipients, this signature mechanism only prevents forgery—not replay of legitimately-signed messages from previous rounds. The `DkgBegin` message structure contains only a `dkg_id` field with no timestamp, nonce, or other replay protection mechanism. [7](#0-6) 

Signature verification occurs in the signer's message processing flow, confirming message authenticity but providing no temporal or replay protection. [8](#0-7) 

**Critical Test Gap:**

The test named `old_round_ids_are_ignored` is misleading—it sets `old_id = id` on line 1513, making them equal rather than testing actual regression where `old_id < id`. This means the test only validates duplicate detection (where `old_id == current_id`), not the critical case of regression to genuinely older rounds. [9](#0-8) 

## Impact Explanation

This vulnerability allows an attacker with the ability to send messages through the protocol's RPC/P2P interface to force protocol participants to regress to previous DKG rounds by replaying old legitimately-signed `DkgBegin` messages.

**Concrete Attack Scenario:**
1. The network is operating at DKG round 15
2. Attacker replays a previously captured `DkgBegin{dkg_id: 10}` message with valid coordinator signature
3. Recipients process this message and regress to round 10, abandoning current DKG progress
4. If the replay reaches only some nodes, the network becomes desynchronized with different nodes operating in different DKG rounds
5. DKG cannot complete when participants are in different rounds, as they will be generating shares for different round IDs
6. Failed DKG prevents generation of threshold signing keys required for consensus operations

**Severity Assessment:** This maps to **MEDIUM severity** under "Any transient consensus failures" because:
- Failed DKG rounds prevent threshold signature generation that may be required for consensus operations
- The attack causes temporary disruption to protocol operations requiring coordinated recovery
- Different nodes regressing to different rounds creates a desynchronization state that prevents DKG completion
- Recovery requires coordination to restart DKG from a synchronized state

The impact could escalate toward **HIGH severity** ("Any unintended chain split or network partition") if different sets of nodes become persistently desynchronized in different DKG rounds, though the actual impact depends on how WSTS is integrated into the larger system and available recovery mechanisms.

## Likelihood Explanation

**Attacker Requirements:**
- Ability to observe network traffic to capture legitimately-signed `DkgBegin` messages (standard capability for network adversaries)
- Ability to send messages through the protocol's RPC/P2P interface
- No cryptographic breaks, key compromise, or privileged access required

**Attack Complexity:** LOW
1. Passively observe and capture any `DkgBegin` message during normal protocol operation
2. Wait for the protocol to advance to a later DKG round
3. Send/replay the captured message to reachable nodes through the protocol interface
4. Nodes will regress due to the missing monotonicity checks, accepting the older round ID

**Mitigating Factors:**
- Transport-layer protections (TCP sequence numbers, TLS session state) may prevent some replay scenarios at the network layer
- Actual exploitability depends on the deployment architecture and how WSTS is integrated
- Requires an active network adversary with message injection capability, not just passive observation

**Overall Likelihood:** MEDIUM to HIGH in adversarial network environments where attackers can send messages through the protocol interface, though specific likelihood depends on transport layer protections and deployment architecture. The protocol-level vulnerability is confirmed, but practical exploitability varies with integration details.

## Recommendation

Implement monotonicity validation by rejecting `DkgBegin` messages where `dkg_id` is less than or equal to the current round ID:

**For Coordinators (FROST and FIRE):**
```rust
if let Message::DkgBegin(dkg_begin) = &packet.msg {
    if dkg_begin.dkg_id <= self.current_dkg_id {
        // Reject both duplicate and regressive DKG rounds
        return Ok((None, None));
    }
    // use dkg_id from DkgBegin
    let packet = self.start_dkg_round(Some(dkg_begin.dkg_id))?;
    return Ok((Some(packet), None));
}
```

**For Signers:**
```rust
fn dkg_begin<R: RngCore + CryptoRng>(
    &mut self,
    dkg_begin: &DkgBegin,
    rng: &mut R,
) -> Result<Vec<Message>, Error> {
    if dkg_begin.dkg_id <= self.dkg_id {
        // Reject regressive or duplicate DKG rounds
        return Ok(Vec::new());
    }
    self.reset(dkg_begin.dkg_id, rng);
    self.move_to(State::DkgPublicDistribute)?;
    self.dkg_public_begin(rng)
}
```

**Update Test:**
Fix the `old_round_ids_are_ignored` test to actually test regression:
```rust
let id: u64 = 10;
let old_id = id - 1;  // Actually test a smaller ID
coordinator.current_dkg_id = id;
```

Apply the same monotonicity checks to `NonceRequest` messages for signing rounds.

## Proof of Concept

```rust
#[test]
fn test_dkg_round_regression_vulnerability() {
    use wsts::state_machine::coordinator::frost::Coordinator as FrostCoordinator;
    use wsts::state_machine::coordinator::Coordinator;
    use wsts::net::{Message, Packet, DkgBegin};
    use wsts::curve::scalar::Scalar;
    use rand_core::OsRng;
    
    let mut rng = OsRng;
    let mut config = Config::new(10, 40, 28, Scalar::random(&mut rng));
    config.verify_packet_sigs = false;
    let mut coordinator = FrostCoordinator::<v1::Aggregator>::new(config);
    
    // Set current DKG round to 15
    coordinator.current_dkg_id = 15;
    
    // Attacker replays DkgBegin message from round 10 (older than current)
    let old_dkg_begin = Packet {
        sig: vec![],
        msg: Message::DkgBegin(DkgBegin { dkg_id: 10 }),
    };
    
    let (packet, result) = coordinator.process(&old_dkg_begin).unwrap();
    
    // VULNERABILITY: Coordinator should reject this old round, but instead accepts it
    // and regresses from round 15 to round 10
    assert_eq!(coordinator.current_dkg_id, 10); // Regression occurred!
    assert!(packet.is_some()); // Coordinator processed the old message
    
    // This demonstrates the vulnerability - the coordinator regressed from round 15 to 10
}
```

### Citations

**File:** src/state_machine/signer/mod.rs (L417-432)
```rust
    pub fn reset<T: RngCore + CryptoRng>(&mut self, dkg_id: u64, rng: &mut T) {
        self.dkg_id = dkg_id;
        self.commitments.clear();
        self.decrypted_shares.clear();
        self.decryption_keys.clear();
        self.invalid_private_shares.clear();
        self.public_nonces.clear();
        self.signer.reset_polys(rng);
        self.dkg_public_shares.clear();
        self.dkg_private_shares.clear();
        self.dkg_private_begin_msg = None;
        self.dkg_end_begin_msg = None;
        self.kex_private_key = Scalar::random(rng);
        self.kex_public_keys.clear();
        self.state = State::Idle;
    }
```

**File:** src/state_machine/signer/mod.rs (L463-472)
```rust
        if self.verify_packet_sigs {
            let Some(coordinator_public_key) = self.coordinator_public_key else {
                return Err(Error::MissingCoordinatorPublicKey);
            };
            if !packet.verify(&self.public_keys, &coordinator_public_key) {
                return Err(Error::InvalidPacketSignature);
            }
        }
        let out_msgs = match &packet.msg {
            Message::DkgBegin(dkg_begin) => self.dkg_begin(dkg_begin, rng),
```

**File:** src/state_machine/signer/mod.rs (L844-855)
```rust
    fn dkg_begin<R: RngCore + CryptoRng>(
        &mut self,
        dkg_begin: &DkgBegin,
        rng: &mut R,
    ) -> Result<Vec<Message>, Error> {
        self.reset(dkg_begin.dkg_id, rng);
        self.move_to(State::DkgPublicDistribute)?;

        //let _party_state = self.signer.save();

        self.dkg_public_begin(rng)
    }
```

**File:** src/state_machine/coordinator/frost.rs (L75-82)
```rust
                    if let Message::DkgBegin(dkg_begin) = &packet.msg {
                        if self.current_dkg_id == dkg_begin.dkg_id {
                            // We have already processed this DKG round
                            return Ok((None, None));
                        }
                        // use dkg_id from DkgBegin
                        let packet = self.start_dkg_round(Some(dkg_begin.dkg_id))?;
                        return Ok((Some(packet), None));
```

**File:** src/state_machine/coordinator/frost.rs (L957-966)
```rust
    fn start_dkg_round(&mut self, dkg_id: Option<u64>) -> Result<Packet, Error> {
        if let Some(id) = dkg_id {
            self.current_dkg_id = id;
        } else {
            self.current_dkg_id = self.current_dkg_id.wrapping_add(1);
        }
        info!("Starting DKG round {}", self.current_dkg_id);
        self.move_to(State::DkgPublicDistribute)?;
        self.start_public_shares()
    }
```

**File:** src/state_machine/coordinator/frost.rs (L1507-1538)
```rust
    fn old_round_ids_are_ignored<Aggregator: AggregatorTrait>() {
        let mut rng = create_rng();
        let mut config = Config::new(10, 40, 28, Scalar::random(&mut rng));
        config.verify_packet_sigs = false;
        let mut coordinator = FrostCoordinator::<Aggregator>::new(config);
        let id: u64 = 10;
        let old_id = id;
        coordinator.current_dkg_id = id;
        coordinator.current_sign_id = id;
        // Attempt to start an old DKG round
        let (packet, result) = coordinator
            .process(&Packet {
                sig: vec![],
                msg: Message::DkgBegin(DkgBegin { dkg_id: old_id }),
            })
            .unwrap();
        assert!(packet.is_none());
        assert!(result.is_none());
        assert_eq!(coordinator.state, State::Idle);
        assert_eq!(coordinator.current_dkg_id, id);

        // Attempt to start the same DKG round
        let (packet, result) = coordinator
            .process(&Packet {
                sig: vec![],
                msg: Message::DkgBegin(DkgBegin { dkg_id: id }),
            })
            .unwrap();
        assert!(packet.is_none());
        assert!(result.is_none());
        assert_eq!(coordinator.state, State::Idle);
        assert_eq!(coordinator.current_dkg_id, id);
```

**File:** src/state_machine/coordinator/fire.rs (L230-237)
```rust
                    if let Message::DkgBegin(dkg_begin) = &packet.msg {
                        if self.current_dkg_id == dkg_begin.dkg_id {
                            // We have already processed this DKG round
                            return Ok((None, None));
                        }
                        // use dkg_id from DkgBegin
                        let packet = self.start_dkg_round(Some(dkg_begin.dkg_id))?;
                        return Ok((Some(packet), None));
```

**File:** src/state_machine/coordinator/fire.rs (L1429-1439)
```rust
    fn start_dkg_round(&mut self, dkg_id: Option<u64>) -> Result<Packet, Error> {
        if let Some(id) = dkg_id {
            self.current_dkg_id = id;
        } else {
            self.current_dkg_id = self.current_dkg_id.wrapping_add(1);
        }

        info!("Starting DKG round {}", self.current_dkg_id);
        self.move_to(State::DkgPublicDistribute)?;
        self.start_public_shares()
    }
```

**File:** src/net.rs (L127-137)
```rust
pub struct DkgBegin {
    /// DKG round ID
    pub dkg_id: u64,
}

impl Signable for DkgBegin {
    fn hash(&self, hasher: &mut Sha256) {
        hasher.update("DKG_BEGIN".as_bytes());
        hasher.update(self.dkg_id.to_be_bytes());
    }
}
```
