# Audit Report

## Title
NonceResponse Accepts Duplicate key_ids Causing Signature Verification Failure

## Summary
A malicious signer can inject duplicate key IDs in their NonceResponse message, bypassing HashSet-based validation while corrupting Lagrange interpolation coefficients for all participants. This causes all subsequent group signatures to fail verification, resulting in a denial of service for the threshold signing group.

## Finding Description

The vulnerability exists in the coordinator's NonceResponse validation logic. The coordinator validates incoming NonceResponse messages by converting the `key_ids` vector to a HashSet for comparison against configured signer key IDs, which automatically deduplicates any duplicate values: [1](#0-0) 

This allows a malicious NonceResponse with `key_ids: [3, 4, 4]` to pass validation when the configured set is `{3, 4}`. The NonceResponse structure itself allows arbitrary length vectors for both key_ids and nonces: [2](#0-1) 

Critically, there is no validation that key_ids contains no duplicate values. When the coordinator gathers signature shares, it collects key_ids from all NonceResponses using `flat_map`, which preserves the duplicates: [3](#0-2) 

These corrupted key_ids are distributed to all signers via SignatureShareRequest. Each signer extracts the key_ids using the same flat_map pattern: [4](#0-3) 

All parties then use these corrupted key_ids to compute Lagrange interpolation coefficients. In the v2 signer implementation, each party computes their signature share using the lambda function with the corrupted key_ids array: [5](#0-4) 

The `compute::lambda` function iterates over all key_ids to compute the Lagrange coefficient: [6](#0-5) 

When key_ids contains duplicates (e.g., `[1, 2, 3, 4, 4]`), the lambda calculation becomes incorrect. For key_id=1, it computes `(2/(2-1)) * (3/(3-1)) * (4/(4-1)) * (4/(4-1)) = 16/3`, whereas the correct value should be `lambda(1, [1, 2, 3, 4]) = 4`.

Since all participants use the same corrupted key_ids array, they all compute incorrect Lagrange coefficients. The aggregator's check_signature_shares method also uses the same corrupted key_ids: [7](#0-6) 

This means individual signature share checks pass (all parties used the same wrong coefficients), but the final signature verification fails because it checks against the fixed group public key established during DKG: [8](#0-7) [9](#0-8) 

The signature verification equation `z * G - c * public_key == R` fails because z was computed with incorrect Lagrange coefficients that do not properly reconstruct the group secret key via polynomial interpolation.

## Impact Explanation

**Severity: Low** (Denial of Service)

This vulnerability allows a single malicious signer to prevent any valid signatures from being produced by the threshold signing group. The attack prevents legitimate operations without causing permanent damage:

- All honest signers compute signature shares using incorrect Lagrange coefficients
- The aggregator successfully combines shares but produces an invalid group signature
- Signature verification fails against the fixed group public key established during DKG
- The signing round must be aborted and restarted
- No valid signatures can be produced while the malicious signer continues the attack

In blockchain contexts using WSTS for threshold signatures:
- Multi-signature wallets cannot sign transactions
- Validator groups cannot sign blocks
- Service degradation proportional to affected signing groups

This maps to **Low severity** as defined in the scope: "Any remotely-exploitable denial of service in a node." The attack does not cause permanent loss of funds, chain splits, network shutdown, or consensus failures. Recovery requires identifying and removing the malicious signer, then reconfiguring the signing group.

## Likelihood Explanation

**Likelihood: High**

**Required Attacker Capabilities:**
- Control over a single signer in a threshold signing group (within protocol threat model)
- Ability to construct malicious NonceResponse messages
- No cryptographic breaks or key compromises required

**Attack Complexity:**
The attack is trivial to execute. The attacker constructs a NonceResponse with duplicate key_ids. For v2/WSTS where each signer generates one nonce regardless of key count, the attack could be:
- Normal: `NonceResponse { key_ids: [3, 4], nonces: [n], ... }`
- Attack: `NonceResponse { key_ids: [3, 4, 4], nonces: [n], ... }` (or with additional fake nonces)

The HashSet validation passes because `{3, 4, 4} == {3, 4}`, while downstream processing preserves the duplicates in the flat_mapped key_ids array used for Lagrange coefficient computation.

**Detection:**
The attack is immediately apparent after the first failed signature verification, but identifying the specific malicious signer requires examining raw NonceResponse messages, as coordinator logs show "valid" responses that passed HashSet validation.

**Success Rate:**
Near 100% for causing denial of service. Any signer in any signing group can execute this attack at will during any signing round.

## Recommendation

Add validation to ensure key_ids contains no duplicate values. In both `fire.rs` and `frost.rs` coordinators, after the HashSet comparison, add:

```rust
if nonce_response.key_ids.len() != nonce_response_key_ids.len() {
    warn!(signer_id = %nonce_response.signer_id, "Nonce response contains duplicate key_ids");
    return Ok(());
}
```

This checks that the original vector length matches the deduplicated HashSet length, rejecting any NonceResponse with duplicate key_ids before they can corrupt the global key_ids array used for Lagrange interpolation.

Alternatively, replace the existing HashSet comparison with a more comprehensive check that validates both uniqueness and set equality simultaneously.

## Proof of Concept

A proof of concept would involve:
1. Setting up a threshold signing group with 2-of-3 configuration
2. Having signer 2 send: `NonceResponse { key_ids: [3, 4, 4], nonces: [n], ... }`
3. Observing that the HashSet validation passes (lines 881-889 in fire.rs)
4. Collecting all key_ids via flat_map results in `[1, 2, 3, 4, 4]`
5. All signers compute signature shares with `lambda(key_id, [1, 2, 3, 4, 4])`
6. Signature aggregation succeeds (shares are internally consistent)
7. Final signature verification fails: `sig.verify(&group_key, msg)` returns false

The test would verify that with duplicate key_ids, `lambda(1, [1, 2, 3, 4, 4])` produces 16/3 instead of the correct value 4, and that the final aggregated signature fails verification against the DKG-established group public key.

### Citations

**File:** src/state_machine/coordinator/fire.rs (L881-889)
```rust
            let nonce_response_key_ids = nonce_response
                .key_ids
                .iter()
                .cloned()
                .collect::<HashSet<u32>>();
            if *signer_key_ids != nonce_response_key_ids {
                warn!(signer_id = %nonce_response.signer_id, "Nonce response key_ids didn't match config");
                return Ok(());
            }
```

**File:** src/state_machine/coordinator/fire.rs (L1126-1129)
```rust
            let key_ids = nonce_responses
                .iter()
                .flat_map(|nr| nr.key_ids.clone())
                .collect::<Vec<u32>>();
```

**File:** src/net.rs (L320-323)
```rust
    /// Key IDs
    pub key_ids: Vec<u32>,
    /// Public nonces
    pub nonces: Vec<PublicNonce>,
```

**File:** src/state_machine/signer/mod.rs (L800-804)
```rust
            let key_ids: Vec<u32> = sign_request
                .nonce_responses
                .iter()
                .flat_map(|nr| nr.key_ids.iter().copied())
                .collect::<Vec<u32>>();
```

**File:** src/v2.rs (L262-265)
```rust
        let mut cx = Scalar::zero();
        for key_id in self.key_ids.iter() {
            cx += c * &self.private_keys[key_id] * compute::lambda(*key_id, key_ids);
        }
```

**File:** src/v2.rs (L389-409)
```rust
        for i in 0..sig_shares.len() {
            let z_i = sig_shares[i].z_i;
            let mut cx = Point::zero();

            for key_id in &sig_shares[i].key_ids {
                let kid = compute::id(*key_id);
                let public_key = match compute::poly(&kid, &self.poly) {
                    Ok(p) => p,
                    Err(_) => {
                        bad_party_keys.push(sig_shares[i].id);
                        Point::zero()
                    }
                };

                cx += compute::lambda(*key_id, key_ids) * c * public_key;
            }

            if z_i * G != (r_sign * Rs[i] + cx_sign * cx) {
                bad_party_sigs.push(sig_shares[i].id);
            }
        }
```

**File:** src/v2.rs (L455-461)
```rust
        let (key, sig) = self.sign_with_tweak(msg, nonces, sig_shares, key_ids, None)?;

        if sig.verify(&key, msg) {
            Ok(sig)
        } else {
            Err(self.check_signature_shares(msg, nonces, sig_shares, key_ids, None))
        }
```

**File:** src/compute.rs (L70-80)
```rust
pub fn lambda(i: u32, key_ids: &[u32]) -> Scalar {
    let mut lambda = Scalar::one();
    let i_scalar = id(i);
    for j in key_ids {
        if i != *j {
            let j_scalar = id(*j);
            lambda *= j_scalar / (j_scalar - i_scalar);
        }
    }
    lambda
}
```

**File:** src/common.rs (L245-250)
```rust
    pub fn verify(&self, public_key: &Point, msg: &[u8]) -> bool {
        let c = challenge(public_key, &self.R, msg);
        let R = &self.z * G + (-c) * public_key;

        R == self.R
    }
```
