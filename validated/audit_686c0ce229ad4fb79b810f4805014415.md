# Audit Report

## Title
Coordinator Panic Due to Premature Signer Removal from Wait List During Signature Share Gathering

## Summary
The `gather_sig_shares()` function in the FIRE coordinator removes signers from the wait list before validating their signature share responses. When validation fails, the signer is absent from both the wait list and the signature shares map, causing a panic during aggregation when the coordinator attempts to access the missing entry using BTreeMap's indexing operator.

## Finding Description

The vulnerability exists in the signature share gathering logic where the coordinator processes responses from signers. The core issue is a violation of the atomicity principle: the signer is removed from the wait list before their response is validated, creating an inconsistent state when validation fails.

**Attack Flow:**

1. **Setup**: Two signers (A and B) complete nonce exchange and are both present in `public_nonces` and `sign_wait_signer_ids`

2. **Malicious Signer A sends invalid response**:
   - Coordinator receives SignatureShareResponse from Signer A
   - Signer A is removed from wait list [1](#0-0) 
   - Validation checks execute and fail (e.g., key_ids mismatch) [2](#0-1) 
   - Function returns error early
   - Signer A is NOT added to `signature_shares` (only happens at lines 1088-1090 after successful validation)
   - State remains `SigShareGather`

3. **Honest Signer B sends valid response**:
   - Signer B is removed from wait list
   - Validation passes
   - Signer B is added to `signature_shares` [3](#0-2) 
   - Wait list is now empty (both A and B removed)
   - Aggregation triggers [4](#0-3) 

4. **Panic occurs during aggregation**:
   - Code iterates over all signers in `public_nonces` (includes both A and B) [5](#0-4) 
   - Attempts to access `self.signature_shares[A]` using BTreeMap's `[]` operator
   - BTreeMap panics when key doesn't exist
   - Coordinator crashes

**Why Existing Protections Fail:**

- The timeout handler only marks signers still in the wait list as malicious, missing those already removed [6](#0-5) 
- No threshold validation occurs before aggregation; only an empty wait list check
- No defensive programming (`.get()` vs `[]`) protects against missing entries
- The data structure types are BTreeMap [7](#0-6)  which panics on missing keys with the index operator

## Impact Explanation

This vulnerability enables a **remotely-exploitable denial of service** against the coordinator node, classified as **LOW severity** per the audit scope definition: "Any remotely-exploitable denial of service in a node."

**Concrete Harm:**
- Immediate coordinator process termination via panic
- All pending signature operations fail
- Indefinite DoS (attacker can repeat on restart)
- All participants waiting for signature completion are affected

**Why Not Higher Severity:**
- Does not produce invalid signatures (crashes before aggregation completes)
- Does not cause direct fund loss
- Does not cause consensus failures
- Does not enable persistent code execution

The impact is limited to availability (DoS) without compromising integrity or confidentiality of the threshold signature protocol.

## Likelihood Explanation

**Likelihood: HIGH**

**Attacker Requirements:**
- Must be a configured signer (within protocol threat model)
- Network access to send messages to coordinator
- No cryptographic capabilities needed
- No exploitation of race conditions or timing required

**Attack Complexity: LOW**
1. Participate normally in nonce gathering phase
2. Send SignatureShareResponse with mismatched `key_ids`
3. Wait for another signer's response to empty the wait list
4. Coordinator panics deterministically

**Success Rate: 100%** - The panic is deterministic once the conditions are met (malicious signer removed from wait list, honest signer empties wait list).

**Economic Feasibility:** Negligible cost - only requires crafting one malformed message.

**Detection:** Low initial detection risk; appears as validation error followed by crash, potentially mistaken for a bug rather than an attack.

## Recommendation

**Fix 1: Use Defensive Access Pattern**
Replace the panic-inducing index operator with safe access:

```rust
let shares = message_nonce
    .public_nonces
    .iter()
    .filter_map(|(i, _)| self.signature_shares.get(i).cloned())
    .flatten()
    .collect::<Vec<SignatureShare>>();
```

**Fix 2: Atomic Remove-and-Validate** (Preferred)
Move the wait list removal to after successful validation:

```rust
// Remove these lines from before validation (1042-1044)
// Instead, add after successful validation at line 1090:
response_info
    .sign_wait_signer_ids
    .remove(&sig_share_response.signer_id);
```

**Fix 3: Add Threshold Check**
Before aggregation, verify sufficient valid shares:

```rust
if message_nonce.sign_wait_signer_ids.is_empty() {
    let valid_share_count = self.signature_shares.len();
    if valid_share_count < self.config.threshold as usize {
        return Err(Error::InsufficientSignatureShares);
    }
    // Continue with aggregation...
}
```

## Proof of Concept

```rust
#[test]
#[should_panic(expected = "no entry found for key")]
fn test_coordinator_panic_on_invalid_sig_share() {
    use crate::v2;
    use crate::state_machine::coordinator::fire::Coordinator as FireCoordinator;
    use crate::traits::Aggregator as AggregatorTrait;
    
    // Setup coordinator with 2 signers, threshold 2
    let mut rng = create_rng();
    let config = Config::new(2, 2, 2, Scalar::random(&mut rng));
    let mut coordinator = FireCoordinator::<v2::Aggregator>::new(config);
    
    // Run DKG to completion
    // ... (DKG setup code)
    
    // Start signing round, both signers send valid nonces
    // ... (nonce exchange code)
    
    // Signer 0 sends INVALID signature share (wrong key_ids)
    let invalid_response = SignatureShareResponse {
        dkg_id: coordinator.current_dkg_id,
        sign_id: coordinator.current_sign_id,
        sign_iter_id: coordinator.current_sign_iter_id,
        signer_id: 0,
        signature_shares: vec![/* shares with wrong key_ids */],
    };
    let _ = coordinator.process_message(&Packet {
        sig: vec![],
        msg: Message::SignatureShareResponse(invalid_response),
    });
    
    // Signer 1 sends VALID signature share
    let valid_response = SignatureShareResponse {
        dkg_id: coordinator.current_dkg_id,
        sign_id: coordinator.current_sign_id,
        sign_iter_id: coordinator.current_sign_iter_id,
        signer_id: 1,
        signature_shares: vec![/* valid shares */],
    };
    
    // This will panic at line 1134 when trying to access signature_shares[0]
    coordinator.process_message(&Packet {
        sig: vec![],
        msg: Message::SignatureShareResponse(valid_response),
    }).unwrap();
}
```

**Notes:**
- The vulnerability is triggered when at least one signer sends an invalid response that fails validation after wait list removal, followed by enough valid responses to empty the wait list
- The panic occurs specifically at the BTreeMap index operation, not during cryptographic operations
- This is a state management bug, not a cryptographic vulnerability
- The fix should prioritize atomic operations (validate-then-remove) over defensive access patterns to maintain code clarity

### Citations

**File:** src/state_machine/coordinator/fire.rs (L45-45)
```rust
    signature_shares: BTreeMap<u32, Vec<SignatureShare>>,
```

**File:** src/state_machine/coordinator/fire.rs (L178-186)
```rust
                            for signer_id in &self
                                .message_nonces
                                .get(&self.message)
                                .ok_or(Error::MissingMessageNonceInfo)?
                                .sign_wait_signer_ids
                            {
                                warn!("Mark signer {signer_id} as malicious");
                                self.malicious_signer_ids.insert(*signer_id);
                            }
```

**File:** src/state_machine/coordinator/fire.rs (L1042-1044)
```rust
        response_info
            .sign_wait_signer_ids
            .remove(&sig_share_response.signer_id);
```

**File:** src/state_machine/coordinator/fire.rs (L1073-1076)
```rust
        if *signer_key_ids != sig_share_response_key_ids {
            warn!(signer_id = %sig_share_response.signer_id, "SignatureShareResponse key_ids didn't match config");
            return Err(Error::BadKeyIDsForSigner(sig_share_response.signer_id));
        }
```

**File:** src/state_machine/coordinator/fire.rs (L1088-1090)
```rust
        self.signature_shares.insert(
            sig_share_response.signer_id,
            sig_share_response.signature_shares.clone(),
```

**File:** src/state_machine/coordinator/fire.rs (L1113-1113)
```rust
        if message_nonce.sign_wait_signer_ids.is_empty() {
```

**File:** src/state_machine/coordinator/fire.rs (L1131-1135)
```rust
            let shares = message_nonce
                .public_nonces
                .iter()
                .flat_map(|(i, _)| self.signature_shares[i].clone())
                .collect::<Vec<SignatureShare>>();
```
