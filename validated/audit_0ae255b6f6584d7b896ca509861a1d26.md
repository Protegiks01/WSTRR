# Audit Report

## Title
Unbounded Message Serialization Sizes Enable Memory Exhaustion DoS

## Summary
The WSTS library processes and stores DKG messages without validating vector sizes before resource consumption. Malicious signers can craft `DkgPublicShares` messages with arbitrarily large polynomial commitments that are signature-verified (consuming CPU) and stored (consuming memory) before size validation occurs, enabling denial of service attacks.

## Finding Description

The `DkgPublicShares` message structure contains two unbounded vector fields that enable resource exhaustion attacks. The `comms` field is defined as `Vec<(u32, PolyCommitment)>` with no maximum size constraint [1](#0-0) , and each `PolyCommitment` contains an unbounded `poly: Vec<Point>` field [2](#0-1) .

When signature verification is enabled (the default configuration [3](#0-2) ), the verification process calls the `hash()` method which iterates through all entries in `comms` and all Points in each polynomial, performing point compression operations on each Point [4](#0-3) . This signature verification occurs before any size validation [5](#0-4) .

After successful signature verification, the coordinator's `gather_public_shares` function immediately clones and stores the entire message in state without checking vector bounds [6](#0-5) . The same vulnerable pattern exists in the FROST coordinator implementation [7](#0-6) .

The `check_public_shares` validation function only verifies that the polynomial length equals the configured threshold [8](#0-7) . This validation does not enforce reasonable absolute bounds on vector sizes. Critically, this validation occurs much later during the DkgEnd phase in both the coordinator [9](#0-8)  and signer [10](#0-9) , after CPU and memory resources have already been consumed during signature verification and storage.

A malicious signer can construct messages with arbitrary vector sizes (e.g., 10,000 comms entries with 10,000 Points each) and sign them with their valid private key. The threshold value is read from configuration [11](#0-10) , so the oversized polynomial will eventually be rejected for not matching the configured threshold, but only after resources are exhausted.

## Impact Explanation

This vulnerability enables remotely-exploitable denial of service against coordinator and signer nodes. A malicious registered signer can craft `DkgPublicShares` messages with excessive polynomial commitments (e.g., 10,000 entries × 10,000 Points each). When received, the node must:

1. **CPU Exhaustion**: Hash the entire message during signature verification, iterating through millions of Points and performing elliptic curve point compression operations
2. **Memory Exhaustion**: Clone and store the entire oversized message structure in state

Since DKG completion is required before any threshold signatures can be generated, preventing DKG through DoS prevents the entire signing functionality. This maps to **"Low: Any remotely-exploitable denial of service in a node"** in the protocol scope, as it renders nodes unresponsive and prevents signature generation without completely shutting down the network.

## Likelihood Explanation

**High Likelihood** - The attack is trivially exploitable:

**Required Attacker Capabilities:**
- Must be a registered signer with valid credentials (within protocol threat model)
- Ability to send network messages to coordinators

**Attack Complexity:** Very Low
- Construct oversized message by populating vectors with excessive elements
- Sign with valid private key (no cryptographic bypasses needed)
- No race conditions or timing dependencies

**Success Probability:** High
- Works immediately upon message receipt
- Affects all coordinator/signer implementations
- Repeatable across DKG rounds
- No size limits exist to reject messages before processing

## Recommendation

Implement early size validation before resource-intensive operations:

1. **Add maximum size constants** for vectors in DkgPublicShares:
   - Define `MAX_COMMS_ENTRIES` (e.g., num_keys * 2)
   - Define `MAX_POLY_LENGTH` (e.g., threshold + reasonable buffer)

2. **Validate sizes before signature verification** in the message processing flow:
   - Check `comms.len() <= MAX_COMMS_ENTRIES`
   - Check each `poly.len() <= MAX_POLY_LENGTH`
   - Reject messages that exceed limits before calling `verify()`

3. **Implement bounded deserialization** to prevent oversized messages from being fully deserialized.

## Proof of Concept

```rust
#[test]
fn test_oversized_dkg_public_shares_dos() {
    // Create a malicious DkgPublicShares with 10,000 comms entries
    // Each with a poly containing 10,000 Points
    let mut malicious_comms = Vec::new();
    for party_id in 0..10000 {
        let mut poly = Vec::new();
        for _ in 0..10000 {
            poly.push(Point::generator()); // 10,000 points per poly
        }
        let poly_comm = PolyCommitment {
            id: ID::new(&Scalar::random(&mut rng), &poly[0], &[]),
            poly,
        };
        malicious_comms.push((party_id, poly_comm));
    }
    
    let malicious_msg = DkgPublicShares {
        dkg_id: 1,
        signer_id: 1,
        comms: malicious_comms, // 10,000 × 10,000 = 100M Points
        kex_public_key: Point::generator(),
    };
    
    // Measure resource consumption during hash (signature verification)
    let start = Instant::now();
    let mut hasher = Sha256::new();
    malicious_msg.hash(&mut hasher); // Iterates through 100M Points
    let duration = start.elapsed();
    
    // Assert that processing takes significant time (CPU exhaustion)
    assert!(duration.as_secs() > 10); // Will take many seconds
    
    // Assert that message size is excessive (memory exhaustion)
    let serialized_size = bincode::serialize(&malicious_msg).unwrap().len();
    assert!(serialized_size > 1_000_000_000); // > 1GB
}
```

### Citations

**File:** src/net.rs (L147-147)
```rust
    pub comms: Vec<(u32, PolyCommitment)>,
```

**File:** src/net.rs (L157-161)
```rust
        for (party_id, comm) in &self.comms {
            hasher.update(party_id.to_be_bytes());
            for a in &comm.poly {
                hasher.update(a.compress().as_bytes());
            }
```

**File:** src/common.rs (L32-32)
```rust
    pub poly: Vec<Point>,
```

**File:** src/common.rs (L319-320)
```rust
pub fn check_public_shares(poly_comm: &PolyCommitment, threshold: usize, ctx: &[u8]) -> bool {
    poly_comm.verify(ctx) && poly_comm.poly.len() == threshold
```

**File:** src/state_machine/coordinator/mod.rs (L198-198)
```rust
            verify_packet_sigs: true,
```

**File:** src/state_machine/coordinator/fire.rs (L218-224)
```rust
        if self.config.verify_packet_sigs {
            let Some(coordinator_public_key) = self.coordinator_public_key else {
                return Err(Error::MissingCoordinatorPublicKey);
            };
            if !packet.verify(&self.config.public_keys, &coordinator_public_key) {
                return Err(Error::InvalidPacketSignature);
            }
```

**File:** src/state_machine/coordinator/fire.rs (L505-506)
```rust
            self.dkg_public_shares
                .insert(dkg_public_shares.signer_id, dkg_public_shares.clone());
```

**File:** src/state_machine/coordinator/fire.rs (L604-604)
```rust
        let threshold: usize = self.config.threshold.try_into().unwrap();
```

**File:** src/state_machine/coordinator/fire.rs (L633-637)
```rust
                                    if !check_public_shares(
                                        comm,
                                        threshold,
                                        &self.current_dkg_id.to_be_bytes(),
                                    ) {
```

**File:** src/state_machine/coordinator/frost.rs (L317-318)
```rust
            self.dkg_public_shares
                .insert(dkg_public_shares.signer_id, dkg_public_shares.clone());
```

**File:** src/state_machine/signer/mod.rs (L557-558)
```rust
                        if !check_public_shares(comm, threshold, &self.dkg_id.to_be_bytes()) {
                            bad_public_shares.insert(*signer_id);
```
