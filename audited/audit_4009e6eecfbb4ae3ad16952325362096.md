# Audit Report

## Title
Fire Coordinator Timeout Logic Incorrectly Marks Honest Signers as Malicious on Network Delays

## Summary
The FIRE coordinator's signature share timeout handler indiscriminately marks all non-responding signers as malicious without cryptographic validation, conflating legitimate network delays with actual malicious behavior. This creates false positives that permanently exclude honest signers from future rounds, progressively reducing signing capacity and potentially causing permanent denial of service.

## Finding Description

The vulnerability exists in the `process_timeout()` function when handling signature share gathering timeouts. When the `sign_timeout` expires during the `SigShareGather` state, the coordinator iterates through all signers in `sign_wait_signer_ids` and marks each one as malicious without any validation. [1](#0-0) 

The `sign_wait_signer_ids` set contains signers who sent valid nonce responses but have not yet sent their signature shares. Signers are added to this wait list when they successfully send nonce responses and are only removed when they send signature share responses. [2](#0-1) [3](#0-2) 

Once marked as malicious, signers are permanently excluded from future signing rounds. When a signer in the `malicious_signer_ids` set sends a nonce response in subsequent rounds, it is silently rejected. [4](#0-3) 

The `malicious_signer_ids` set is never cleared - not during reset operations, and there is no other mechanism to remove signers from this set. The `reset()` function explicitly does not clear this set, and no `.clear()` or `.remove()` operations exist on it anywhere in the codebase. [5](#0-4) 

**Root Cause**: The timeout logic conflates two fundamentally different situations: (1) legitimate network delays or high processing load causing slow responses, and (2) actual malicious behavior such as sending cryptographically invalid signatures or protocol violations. In proper threshold signature protocols, only cryptographically proven malicious behavior should result in permanent exclusion, but the current implementation treats timing delays identically to protocol violations.

**Security Invariant Broken**: The protocol should maintain the property that honest signers experiencing transient network issues can recover and participate in future rounds. This implementation permanently excludes them based solely on timing, breaking protocol liveness guarantees.

## Impact Explanation

**Specific Harm**: Honest signers experiencing network delays are permanently excluded from signing, progressively reducing the total available signing capacity. When the system falls below the threshold, it returns `InsufficientSigners` error and can no longer produce valid signatures. [6](#0-5) 

**Quantified Impact**: Consider a deployment with 10 signers, each controlling 2 key IDs (20 total keys), with a threshold of 14 keys:
- Initial capacity: 20 keys available
- After first timeout affecting 3 slow signers: 14 keys available (exactly at threshold)
- After second timeout affecting 2 more signers: 10 keys available (below threshold - **permanent DoS**)

In blockchain contexts where WSTS is used for block production or transaction signing (like Stacks), this results in:
- Inability to confirm new blocks
- Network unable to process transactions for multiple blocks
- Potential chain halt requiring manual intervention
- Complete network shutdown until coordinator is manually restarted or reconfigured

This maps to **High severity** as "Any remotely-exploitable denial of service" and can escalate to **Critical severity** as "Any network to shut down or otherwise not confirm new valid transactions for multiple blocks."

## Likelihood Explanation

**Natural Occurrence**: This vulnerability can trigger without any attacker through normal network congestion, system load spikes, or transient connectivity issues. Any situation where signature share responses arrive after the configured timeout will cause honest signers to be permanently marked as malicious.

**Attack Complexity**: If exploited maliciously, an attacker only needs to:
- Introduce network delays or packet loss on paths between signers and coordinator
- Delay or drop signature share response packets before they reach the coordinator
- No cryptographic capabilities required
- No privileged access required
- Can use simple network-level delays or traffic shaping

**Cumulative Effect**: Each timeout event permanently reduces system capacity. After enough timeouts (whether natural or induced), the system permanently loses the ability to produce signatures. The probability of triggering increases with:
- Network latency
- System load
- Number of signers
- Tight timeout configurations

**Detection Difficulty**: Delayed packets appear identical to normal network behavior, making malicious delays indistinguishable from benign network issues. This enables plausible deniability for attackers while also meaning legitimate network issues produce the same harmful effects.

## Recommendation

Implement a multi-tier approach to distinguish between transient unavailability and actual malicious behavior:

1. **Separate Timeout Categories**: 
   - Use temporary "slow responder" tracking for timeout-based failures
   - Reserve `malicious_signer_ids` only for cryptographically proven malicious behavior (invalid signatures, failed proofs, protocol violations)

2. **Recovery Mechanism**:
   - Allow signers in the "slow responder" set to be cleared after successful participation in a configurable number of rounds
   - Implement exponential backoff before permanent exclusion
   - Add administrative API to manually clear falsely-flagged signers if needed

3. **Validation Before Exclusion**:
   - When a timeout occurs, allow the signing round to complete with available signers
   - If a late-arriving signature share is cryptographically invalid, THEN mark as malicious
   - If valid but late, mark as slow but allow recovery

4. **Adaptive Timeouts**:
   - Monitor network conditions and adjust timeouts dynamically
   - Provide warnings when approaching timeout thresholds to allow operators to investigate

Example fix structure:
```rust
// Add a separate field for temporarily slow signers
slow_signer_ids: HashSet<u32>,

// In process_timeout(), mark as slow instead of malicious
for signer_id in &sign_wait_signer_ids {
    warn!("Mark signer {signer_id} as slow responder");
    self.slow_signer_ids.insert(*signer_id);
}

// Add recovery mechanism
if successful_participation(&signer_id) {
    self.slow_signer_ids.remove(&signer_id);
}

// Only mark as malicious on cryptographic validation failure
if invalid_signature_proof {
    self.malicious_signer_ids.insert(signer_id);
}
```

## Proof of Concept

The existing test `insufficient_signers_sign` demonstrates this behavior, showing that when signature share timeouts occur, signers are marked as malicious and the system eventually returns `InsufficientSigners` error when too many are flagged. [7](#0-6) 

To demonstrate the vulnerability with honest signers:
1. Start a signing round with N signers above threshold
2. Introduce network delays (>128ms based on test timeouts) for signature share responses
3. Observe timeout triggers and signers marked as malicious
4. Attempt new signing round with previously marked signers
5. Observe their nonce responses are rejected despite being cryptographically valid
6. Repeat until below threshold
7. Observe permanent `InsufficientSigners` error with no recovery mechanism

The vulnerability is proven by the combination of:
- Timeout marking without validation (lines 178-186)
- Permanent rejection of marked signers (lines 903-914)
- No clearing mechanism (lines 1479-1490, grep results)
- Terminal error condition (lines 191-199)

### Citations

**File:** src/state_machine/coordinator/fire.rs (L173-186)
```rust
            State::SigShareGather(signature_type) => {
                if let Some(start) = self.sign_start {
                    if let Some(timeout) = self.config.sign_timeout {
                        if now.duration_since(start) > timeout {
                            warn!("Timeout gathering signature shares for signing round {} iteration {}", self.current_sign_id, self.current_sign_iter_id);
                            for signer_id in &self
                                .message_nonces
                                .get(&self.message)
                                .ok_or(Error::MissingMessageNonceInfo)?
                                .sign_wait_signer_ids
                            {
                                warn!("Mark signer {signer_id} as malicious");
                                self.malicious_signer_ids.insert(*signer_id);
                            }
```

**File:** src/state_machine/coordinator/fire.rs (L191-199)
```rust
                            if self.config.num_keys - num_malicious_keys < self.config.threshold {
                                error!("Insufficient non-malicious signers, unable to continue");
                                let mal = self.malicious_signer_ids.iter().copied().collect();
                                return Ok((
                                    None,
                                    Some(OperationResult::SignError(
                                        SignError::InsufficientSigners(mal),
                                    )),
                                ));
```

**File:** src/state_machine/coordinator/fire.rs (L903-914)
```rust
            if self
                .malicious_signer_ids
                .contains(&nonce_response.signer_id)
            {
                warn!(
                    sign_id = %nonce_response.sign_id,
                    sign_iter_id = %nonce_response.sign_iter_id,
                    signer_id = %nonce_response.signer_id,
                    "Received malicious NonceResponse"
                );
                //return Err(Error::MaliciousSigner(nonce_response.signer_id));
                return Ok(());
```

**File:** src/state_machine/coordinator/fire.rs (L940-942)
```rust
            nonce_info
                .sign_wait_signer_ids
                .insert(nonce_response.signer_id);
```

**File:** src/state_machine/coordinator/fire.rs (L1042-1044)
```rust
        response_info
            .sign_wait_signer_ids
            .remove(&sig_share_response.signer_id);
```

**File:** src/state_machine/coordinator/fire.rs (L1479-1490)
```rust
    fn reset(&mut self) {
        self.state = State::Idle;
        self.dkg_public_shares.clear();
        self.dkg_private_shares.clear();
        self.dkg_end_messages.clear();
        self.party_polynomials.clear();
        self.message_nonces.clear();
        self.signature_shares.clear();
        self.dkg_wait_signer_ids.clear();
        self.nonce_start = None;
        self.sign_start = None;
    }
```

**File:** src/state_machine/coordinator/fire.rs (L2936-3184)
```rust
    fn insufficient_signers_sign<Aggregator: AggregatorTrait, Signer: SignerTrait>() {
        let num_signers = 5;
        let keys_per_signer = 2;
        let (mut coordinators, mut signers) =
            setup_with_timeouts::<FireCoordinator<Aggregator>, Signer>(
                num_signers,
                keys_per_signer,
                None,
                None,
                None,
                Some(Duration::from_millis(128)),
                Some(Duration::from_millis(128)),
            );
        let config = coordinators.first().unwrap().get_config();

        // We have started a dkg round
        let message = coordinators
            .first_mut()
            .unwrap()
            .start_dkg_round(None)
            .unwrap();
        assert!(coordinators.first().unwrap().aggregate_public_key.is_none());
        assert_eq!(coordinators.first().unwrap().state, State::DkgPublicGather);

        // Send the DKG Begin message to all signers and gather responses by sharing with all other signers and coordinator
        let (outbound_messages, operation_results) =
            feedback_messages(&mut coordinators, &mut signers, &[message]);
        assert!(operation_results.is_empty());
        for coordinator in &coordinators {
            assert_eq!(coordinator.state, State::DkgPrivateGather);
        }

        assert_eq!(outbound_messages.len(), 1);
        assert!(
            matches!(&outbound_messages[0].msg, Message::DkgPrivateBegin(_)),
            "Expected DkgPrivateBegin message"
        );

        // Send the DKG Private Begin message to all signers and share their responses with the coordinators and signers
        let (outbound_messages, operation_results) =
            feedback_messages(&mut coordinators, &mut signers, &outbound_messages);
        assert!(operation_results.is_empty());
        assert_eq!(outbound_messages.len(), 1);
        assert!(
            matches!(&outbound_messages[0].msg, Message::DkgEndBegin(_)),
            "Expected DkgEndBegin message"
        );

        // Send the DKG End Begin message to all signers and share their responses with the coordinator and signers
        let (outbound_messages, operation_results) =
            feedback_messages(&mut coordinators, &mut signers, &outbound_messages);
        assert!(outbound_messages.is_empty());
        assert_eq!(operation_results.len(), 1);
        let OperationResult::Dkg(point) = operation_results[0] else {
            panic!("Expected Dkg Operationr result");
        };
        assert_ne!(point, Point::default());
        for coordinator in &coordinators {
            assert_eq!(coordinator.aggregate_public_key, Some(point));
            assert_eq!(coordinator.state, State::Idle);
        }

        // Figure out how many signers we can remove and still be above the threshold
        let num_keys = config.num_keys as f64;
        let threshold = config.threshold as f64;
        let num_signers_to_remove =
            (((num_keys - threshold) / keys_per_signer as f64).floor() + 1_f64) as usize;
        let mut insufficient_coordinators = coordinators.clone();
        let mut insufficient_signers = signers.clone();

        insufficient_signers.truncate(
            insufficient_signers
                .len()
                .saturating_sub(num_signers_to_remove),
        );

        // Start a signing round with an insufficient number of signers
        let msg = "It was many and many a year ago, in a kingdom by the sea"
            .as_bytes()
            .to_vec();
        let signature_type = SignatureType::Frost;
        let message = insufficient_coordinators
            .first_mut()
            .unwrap()
            .start_signing_round(&msg, signature_type, None)
            .unwrap();
        assert_eq!(
            insufficient_coordinators.first().unwrap().state,
            State::NonceGather(signature_type)
        );

        // Send the message to all signers and gather responses by sharing with all other signers and coordinator
        let (outbound_messages, operation_results) = feedback_messages(
            &mut insufficient_coordinators,
            &mut insufficient_signers,
            &[message],
        );
        assert!(operation_results.is_empty());
        for coordinator in &insufficient_coordinators {
            assert_eq!(coordinator.state, State::NonceGather(signature_type));
        }

        assert!(outbound_messages.is_empty());

        // Sleep long enough to hit the timeout
        thread::sleep(Duration::from_millis(256));

        let (outbound_message, operation_result) = insufficient_coordinators
            .first_mut()
            .unwrap()
            .process_timeout()
            .unwrap();

        assert!(outbound_message.is_none());
        assert!(operation_result.is_some());
        for coordinator in &insufficient_coordinators {
            assert_eq!(coordinator.state, State::NonceGather(signature_type));
        }

        assert!(
            matches!(
                operation_result.unwrap(),
                OperationResult::SignError(SignError::NonceTimeout(..))
            ),
            "Expected OperationResult::SignError(SignError::NonceTimeout)"
        );

        // Start a new signing round with a sufficient number of signers for nonces but not sig shares
        let mut insufficient_coordinators = coordinators.clone();
        let mut insufficient_signers = signers.clone();

        let message = insufficient_coordinators
            .first_mut()
            .unwrap()
            .start_signing_round(&msg, signature_type, None)
            .unwrap();
        assert_eq!(
            insufficient_coordinators.first().unwrap().state,
            State::NonceGather(signature_type)
        );

        // Send the message to all signers and gather responses by sharing with all other signers and insufficient_coordinator
        let (outbound_messages, operation_results) = feedback_messages(
            &mut insufficient_coordinators,
            &mut insufficient_signers,
            &[message],
        );
        assert!(operation_results.is_empty());
        for coordinator in &insufficient_coordinators {
            assert_eq!(coordinator.state, State::SigShareGather(signature_type));
        }

        assert_eq!(outbound_messages.len(), 1);

        let mut malicious = Vec::new();

        // now remove signers so the number is insufficient
        let num_signers_to_drain = insufficient_signers
            .len()
            .saturating_sub(num_signers_to_remove);
        malicious.extend(insufficient_signers.drain(num_signers_to_drain..));

        // Send the SignatureShareRequest message to all signers and share their responses with the coordinator and signers
        let (outbound_messages, operation_results) = feedback_messages(
            &mut insufficient_coordinators,
            &mut insufficient_signers,
            &outbound_messages,
        );
        assert!(outbound_messages.is_empty());
        assert!(operation_results.is_empty());

        for coordinator in &insufficient_coordinators {
            assert_eq!(coordinator.state, State::SigShareGather(signature_type));
        }

        // Sleep long enough to hit the timeout
        thread::sleep(Duration::from_millis(256));

        let (outbound_message, operation_result) = insufficient_coordinators
            .first_mut()
            .unwrap()
            .process_timeout()
            .unwrap();

        assert!(outbound_message.is_some());
        assert!(operation_result.is_none());
        assert_eq!(
            insufficient_coordinators.first().unwrap().state,
            State::NonceGather(signature_type)
        );

        // put the malicious signers back in
        insufficient_signers.append(&mut malicious);

        // Send the NonceRequest message to all signers and share their responses with the coordinator and signers
        let (outbound_messages, operation_results) = feedback_messages(
            &mut insufficient_coordinators,
            &mut insufficient_signers,
            &[outbound_message.unwrap()],
        );
        assert_eq!(outbound_messages.len(), 1);
        assert!(operation_results.is_empty());

        for coordinator in &insufficient_coordinators {
            assert_eq!(coordinator.state, State::SigShareGather(signature_type));
        }

        // again remove signers so the number is insufficient
        let num_signers_to_drain = insufficient_signers
            .len()
            .saturating_sub(num_signers_to_remove);
        malicious.extend(insufficient_signers.drain(num_signers_to_drain..));

        // Send the SignatureShareRequest message to all signers and share their responses with the coordinator and signers
        let (outbound_messages, operation_results) = feedback_messages(
            &mut insufficient_coordinators,
            &mut insufficient_signers,
            &outbound_messages,
        );
        assert!(outbound_messages.is_empty());
        assert!(operation_results.is_empty());

        for coordinator in &insufficient_coordinators {
            assert_eq!(coordinator.state, State::SigShareGather(signature_type));
        }

        // Sleep long enough to hit the timeout
        thread::sleep(Duration::from_millis(256));

        let (outbound_message, operation_result) = insufficient_coordinators
            .first_mut()
            .unwrap()
            .process_timeout()
            .unwrap();

        assert!(outbound_message.is_none());
        assert!(operation_result.is_some());
        assert_eq!(
            insufficient_coordinators.first_mut().unwrap().state,
            State::SigShareGather(signature_type)
        );
        assert!(
            matches!(
                operation_result.unwrap(),
                OperationResult::SignError(SignError::InsufficientSigners(_))
            ),
            "Expected OperationResult::SignError(SignError::InsufficientSigners)"
        );
    }
```
