# Audit Report

## Title
Missing sign_iter_id Validation in SignatureShareResponse Allows Cross-Iteration Signature Share Replay

## Summary
The FIRE coordinator validates `sign_iter_id` in `NonceResponse` messages but fails to validate it in `SignatureShareResponse` messages. When signature share gathering times out and retries with a new iteration, delayed signature shares from previous iterations can be accepted and aggregated with nonces from the current iteration, causing signature verification to fail and falsely identifying honest signers as malicious.

## Finding Description

The vulnerability exists in the FIRE coordinator's message validation logic, which shows an inconsistency between how `NonceResponse` and `SignatureShareResponse` messages are validated.

**NonceResponse Validation (Correct):**
The coordinator properly validates `sign_iter_id` when processing nonce responses, rejecting messages from previous iterations. [1](#0-0) 

**SignatureShareResponse Validation (Missing):**
The coordinator validates `dkg_id` and `sign_id` but completely omits `sign_iter_id` validation when processing signature share responses. [2](#0-1) 

**Retry Mechanism:**
When signature share gathering times out, the coordinator increments `sign_iter_id` and requests new nonces for a retry attempt. [3](#0-2) [4](#0-3) 

**Critical Vulnerability Flow:**
When `request_nonces()` is called during retry, it clears the entire `message_nonces` map, which stores the `SignRoundInfo` containing nonces and wait lists. [5](#0-4) 

This clearing operation means:
1. Old nonces from iteration N are discarded
2. New nonces from iteration N+1 populate `message_nonces`
3. The `sign_wait_signer_ids` set is repopulated with signers from iteration N+1 [6](#0-5) 

When a delayed `SignatureShareResponse` from iteration N arrives during iteration N+1:
- The wait list check passes if the signer participated in both iterations [7](#0-6) 
- Without `sign_iter_id` validation, the old signature share is accepted
- The coordinator aggregates signature shares from iteration N with nonces from iteration N+1 [8](#0-7) 

**Signature Verification Failure:**
Signature shares are computed as `z_i = d_i + Ï_i * b_i * c` where the binding values depend on the specific nonces used. When signature shares computed with nonces from iteration N are aggregated with nonces from iteration N+1, signature verification fails. The `check_signature_shares` function then verifies each share individually and identifies honest signers as malicious. [9](#0-8) 

**Hash Function Inconsistency:**
The vulnerability is compounded by the fact that `SignatureShareResponse` does not include `sign_iter_id` in its hash function, unlike `NonceResponse` which properly includes it. [10](#0-9) [11](#0-10) 

## Impact Explanation

This vulnerability causes **transient consensus failures** (Medium severity per the defined scope):

1. **False Malicious Accusations:** Honest signers who experience network delays have their signature shares from previous iterations accepted in current iterations, causing verification to fail and falsely identifying them as malicious.

2. **Signing Round Failures:** When mismatched nonces cause signature verification to fail, the entire signing round fails even though all participants were honest.

3. **Potential Denial of Service:** If applications mark parties identified by `BadPartySigs` errors as permanently malicious, enough false accusations could prevent reaching the signing threshold in future rounds, causing a denial of service condition.

4. **Protocol Disruption:** Each failure requires additional retry attempts, which carry further risk of false accusations, potentially creating a cascading failure scenario.

The impact aligns with the Medium severity definition: "Any transient consensus failures" - the vulnerability causes signing operations to fail incorrectly and honest participants to be falsely identified as malicious, disrupting the threshold signature protocol without directly causing fund loss or permanent network shutdown.

## Likelihood Explanation

**Probability: High**

This vulnerability occurs naturally through normal network conditions without any active attacker:

1. **Natural Triggering:** Any network delay that causes a `SignatureShareResponse` to arrive after the coordinator's timeout threshold will trigger this vulnerability.

2. **Zero Attack Cost:** No special capabilities, cryptographic breaks, or privileged access required.

3. **Inevitable Occurrence:** In any deployment with variable network latency and configured timeouts, messages will eventually arrive late, making this vulnerability certain to manifest.

4. **Indistinguishable from Legitimate Errors:** The resulting `BadPartySigs` errors appear identical to actual malicious behavior, making the vulnerability difficult to detect and diagnose.

The coordinator's timeout and retry mechanism is a core feature of the FIRE protocol for handling transient failures, meaning this vulnerability is in a frequently-exercised code path.

## Recommendation

Add `sign_iter_id` validation in the `gather_sig_shares` function, consistent with the validation performed in `gather_nonces`:

```rust
// In gather_sig_shares, after line 1037, add:
if sig_share_response.sign_iter_id != self.current_sign_iter_id {
    return Err(Error::BadSignIterId(
        sig_share_response.sign_iter_id,
        self.current_sign_iter_id,
    ));
}
```

Additionally, include `sign_iter_id` in the `SignatureShareResponse` hash function for consistency:

```rust
// In impl Signable for SignatureShareResponse, after line 454, add:
hasher.update(self.sign_iter_id.to_be_bytes());
```

These changes ensure that only signature shares from the current iteration are accepted, preventing cross-iteration replay and eliminating false malicious accusations due to network delays.

## Proof of Concept

```rust
#[test]
fn test_cross_iteration_signature_share_replay() {
    // Setup coordinator and signers
    let mut rng = rand::thread_rng();
    let config = Config {
        num_keys: 10,
        threshold: 7,
        sign_timeout: Some(Duration::from_millis(100)),
        ..Default::default()
    };
    let mut coordinator = Coordinator::new(config, &mut rng);
    
    // Start signing round - iteration 1
    coordinator.start_signing_round(&message, SignatureType::Frost, None).unwrap();
    coordinator.request_nonces(SignatureType::Frost).unwrap();
    
    // Collect nonces from all signers
    for signer_id in 0..10 {
        let nonce_response = create_nonce_response(signer_id, 1); // sign_iter_id = 1
        coordinator.gather_nonces(&nonce_response, SignatureType::Frost).unwrap();
    }
    
    // Request signature shares
    coordinator.request_sig_shares(SignatureType::Frost).unwrap();
    
    // Signer 0 sends signature share but message is delayed (not delivered yet)
    let delayed_sig_share = create_sig_share_response(0, 1); // sign_iter_id = 1
    
    // Timeout occurs, coordinator moves to iteration 2
    std::thread::sleep(Duration::from_millis(150));
    coordinator.process_timeout(Instant::now()).unwrap();
    
    // Coordinator requests new nonces for iteration 2
    assert_eq!(coordinator.current_sign_iter_id, 2);
    
    // Signers respond with new nonces for iteration 2
    for signer_id in 0..10 {
        let nonce_response = create_nonce_response(signer_id, 2); // sign_iter_id = 2
        coordinator.gather_nonces(&nonce_response, SignatureType::Frost).unwrap();
    }
    
    // Request signature shares for iteration 2
    coordinator.request_sig_shares(SignatureType::Frost).unwrap();
    
    // Delayed signature share from iteration 1 arrives during iteration 2
    // BUG: This should be rejected but is accepted
    let result = coordinator.gather_sig_shares(&delayed_sig_share, SignatureType::Frost);
    
    // The delayed share is accepted (should have been rejected)
    assert!(result.is_ok());
    
    // When enough shares arrive, aggregation fails due to mismatched nonces
    // and signer 0 is falsely identified as malicious
    for signer_id in 1..10 {
        let sig_share = create_sig_share_response(signer_id, 2); // sign_iter_id = 2
        coordinator.gather_sig_shares(&sig_share, SignatureType::Frost).unwrap();
    }
    
    // Aggregation fails with BadPartySigs error falsely accusing signer 0
    match coordinator.aggregate_signature() {
        Err(Error::AggregatorError(AggregatorError::BadPartySigs(bad_parties))) => {
            assert!(bad_parties.contains(&0)); // Honest signer 0 falsely accused
        }
        _ => panic!("Expected BadPartySigs error"),
    }
}
```

### Citations

**File:** src/state_machine/coordinator/fire.rs (L173-204)
```rust
            State::SigShareGather(signature_type) => {
                if let Some(start) = self.sign_start {
                    if let Some(timeout) = self.config.sign_timeout {
                        if now.duration_since(start) > timeout {
                            warn!("Timeout gathering signature shares for signing round {} iteration {}", self.current_sign_id, self.current_sign_iter_id);
                            for signer_id in &self
                                .message_nonces
                                .get(&self.message)
                                .ok_or(Error::MissingMessageNonceInfo)?
                                .sign_wait_signer_ids
                            {
                                warn!("Mark signer {signer_id} as malicious");
                                self.malicious_signer_ids.insert(*signer_id);
                            }

                            let num_malicious_keys: u32 =
                                self.compute_num_key_ids(self.malicious_signer_ids.iter())?;

                            if self.config.num_keys - num_malicious_keys < self.config.threshold {
                                error!("Insufficient non-malicious signers, unable to continue");
                                let mal = self.malicious_signer_ids.iter().copied().collect();
                                return Ok((
                                    None,
                                    Some(OperationResult::SignError(
                                        SignError::InsufficientSigners(mal),
                                    )),
                                ));
                            }

                            self.move_to(State::NonceRequest(signature_type))?;
                            let packet = self.request_nonces(signature_type)?;
                            return Ok((Some(packet), None));
```

**File:** src/state_machine/coordinator/fire.rs (L814-816)
```rust
    fn request_nonces(&mut self, signature_type: SignatureType) -> Result<Packet, Error> {
        self.message_nonces.clear();
        self.current_sign_iter_id = self.current_sign_iter_id.wrapping_add(1);
```

**File:** src/state_machine/coordinator/fire.rs (L856-861)
```rust
            if nonce_response.sign_iter_id != self.current_sign_iter_id {
                return Err(Error::BadSignIterId(
                    nonce_response.sign_iter_id,
                    self.current_sign_iter_id,
                ));
            }
```

**File:** src/state_machine/coordinator/fire.rs (L940-942)
```rust
            nonce_info
                .sign_wait_signer_ids
                .insert(nonce_response.signer_id);
```

**File:** src/state_machine/coordinator/fire.rs (L1015-1025)
```rust
        let waiting = response_info
            .sign_wait_signer_ids
            .contains(&sig_share_response.signer_id);

        if !waiting {
            warn!(
                "Sign round {} SignatureShareResponse for round {} from signer {} not in the wait list",
                self.current_sign_id, sig_share_response.sign_id, sig_share_response.signer_id,
            );
            return Ok(());
        }
```

**File:** src/state_machine/coordinator/fire.rs (L1027-1038)
```rust
        if sig_share_response.dkg_id != self.current_dkg_id {
            return Err(Error::BadDkgId(
                sig_share_response.dkg_id,
                self.current_dkg_id,
            ));
        }
        if sig_share_response.sign_id != self.current_sign_id {
            return Err(Error::BadSignId(
                sig_share_response.sign_id,
                self.current_sign_id,
            ));
        }
```

**File:** src/state_machine/coordinator/fire.rs (L1179-1194)
```rust
        let public_nonces = self
            .message_nonces
            .get(&self.message)
            .cloned()
            .unwrap_or_default()
            .public_nonces;
        let party_ids = public_nonces
            .values()
            .cloned()
            .flat_map(|pn| pn.key_ids)
            .collect::<Vec<u32>>();
        let nonces = public_nonces
            .values()
            .cloned()
            .flat_map(|pn| pn.nonces)
            .collect::<Vec<PublicNonce>>();
```

**File:** src/v1.rs (L361-426)
```rust
    pub fn check_signature_shares(
        &mut self,
        msg: &[u8],
        nonces: &[PublicNonce],
        sig_shares: &[SignatureShare],
        tweak: Option<Scalar>,
    ) -> AggregatorError {
        if nonces.len() != sig_shares.len() {
            return AggregatorError::BadNonceLen(nonces.len(), sig_shares.len());
        }

        let signers: Vec<u32> = sig_shares.iter().map(|ss| ss.id).collect();
        let (Rs, R) = compute::intermediate(msg, &signers, nonces);
        let mut bad_party_keys = Vec::new();
        let mut bad_party_sigs = Vec::new();
        let aggregate_public_key = self.poly[0];
        let tweaked_public_key = match tweak {
            Some(t) if t != Scalar::zero() => {
                compute::tweaked_public_key_from_tweak(&aggregate_public_key, t)
            }
            _ => aggregate_public_key,
        };
        let c = compute::challenge(&tweaked_public_key, &R, msg);
        let mut r_sign = Scalar::one();
        let mut cx_sign = Scalar::one();
        if let Some(t) = tweak {
            if !R.has_even_y() {
                r_sign = -Scalar::one();
            }
            if t != Scalar::zero() {
                if !tweaked_public_key.has_even_y() ^ !aggregate_public_key.has_even_y() {
                    cx_sign = -Scalar::one();
                }
            } else if !aggregate_public_key.has_even_y() {
                cx_sign = -Scalar::one();
            }
        }

        for i in 0..sig_shares.len() {
            let id = compute::id(sig_shares[i].id);
            let public_key = match compute::poly(&id, &self.poly) {
                Ok(p) => p,
                Err(_) => {
                    bad_party_keys.push(sig_shares[i].id);
                    Point::zero()
                }
            };

            let z_i = sig_shares[i].z_i;

            if z_i * G
                != r_sign * Rs[i]
                    + cx_sign * (compute::lambda(sig_shares[i].id, &signers) * c * public_key)
            {
                bad_party_sigs.push(sig_shares[i].id);
            }
        }

        if !bad_party_keys.is_empty() {
            AggregatorError::BadPartyKeys(bad_party_keys)
        } else if !bad_party_sigs.is_empty() {
            AggregatorError::BadPartySigs(bad_party_sigs)
        } else {
            AggregatorError::BadGroupSig
        }
    }
```

**File:** src/net.rs (L350-354)
```rust
    fn hash(&self, hasher: &mut Sha256) {
        hasher.update("NONCE_RESPONSE".as_bytes());
        hasher.update(self.dkg_id.to_be_bytes());
        hasher.update(self.sign_id.to_be_bytes());
        hasher.update(self.sign_iter_id.to_be_bytes());
```

**File:** src/net.rs (L450-464)
```rust
impl Signable for SignatureShareResponse {
    fn hash(&self, hasher: &mut Sha256) {
        hasher.update("SIGNATURE_SHARE_RESPONSE".as_bytes());
        hasher.update(self.dkg_id.to_be_bytes());
        hasher.update(self.sign_id.to_be_bytes());
        hasher.update(self.signer_id.to_be_bytes());

        for signature_share in &self.signature_shares {
            hasher.update(signature_share.id.to_be_bytes());
            hasher.update(signature_share.z_i.to_bytes());
            for key_id in &signature_share.key_ids {
                hasher.update(key_id.to_be_bytes());
            }
        }
    }
```
