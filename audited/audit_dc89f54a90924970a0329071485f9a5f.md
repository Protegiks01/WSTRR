### Title
Memory and CPU Exhaustion via Unbounded PolyCommitment Vector During DKG

### Summary
A malicious signer can send DkgPublicShares messages containing PolyCommitment structures with arbitrarily large poly vectors (millions of elliptic curve points), causing both memory exhaustion during deserialization and severe CPU exhaustion during packet signature verification. This occurs before any polynomial size validation, enabling denial-of-service attacks that prevent DKG completion and block threshold signature generation.

### Finding Description

**Exact Code Location:**

The vulnerability exists in the PolyCommitment structure definition and its processing flow: [1](#0-0) 

The poly field is an unbounded Vec<Point> with no size constraints during deserialization. The size validation function only checks polynomial length equality with threshold: [2](#0-1) 

**Root Cause:**

The vulnerability occurs because expensive operations (deserialization and signature verification) happen BEFORE polynomial size validation in both the coordinator and signer message processing paths.

**Coordinator Processing Path:**

When the coordinator receives DkgPublicShares messages, packet signature verification occurs first: [3](#0-2) 

The actual polynomial size validation only happens much later during DKG end gathering: [4](#0-3) 

**Signer Processing Path:**

Signers follow the same vulnerable pattern - verification before validation: [5](#0-4) 

Size validation only occurs during dkg_ended(): [6](#0-5) 

**Why Packet Verification is Expensive:**

The packet.verify() method calls the message's hash function, which iterates over ALL points in the polynomial and compresses each one: [7](#0-6) 

Point compression involves elliptic curve operations (compress() call on line 160) that are computationally expensive when performed millions of times.

**Why Existing Mitigations Fail:**

1. **No early bounds checking**: Serde deserializes the entire Vec<Point> into memory before any validation
2. **Signature verification before validation**: packet.verify() processes all points before check_public_shares() is ever called
3. **No network-layer message size limits**: No code enforces maximum message sizes during deserialization
4. **Validation occurs too late**: By the time check_public_shares() validates poly.len() == threshold, both memory and CPU resources have already been exhausted

### Impact Explanation

**Specific Harm:**

A malicious signer can prevent DKG completion across the entire signing group, making threshold signature generation impossible. This constitutes a **transient consensus failure** (Medium severity per protocol scope).

**Quantified Impact:**

- **Memory exhaustion**: With 10 million points at ~64 bytes per compressed point, a single malicious PolyCommitment consumes ~640 MB. Multiple commitments in one message (one per party) can consume multiple gigabytes.

- **CPU exhaustion**: Hashing 10 million points with elliptic curve compression operations can take several minutes per message, completely blocking message processing.

- **Affected parties**: 
  - The coordinator becomes unresponsive and cannot complete DKG
  - All honest signers processing the malicious message also become unresponsive
  - The entire DKG round fails, preventing the signing group from forming

**Severity Justification:**

This maps to **Medium severity** ("Any transient consensus failures") because:
- WSTS signers perform critical threshold signing operations
- Failed DKG prevents signature generation for blocks/transactions
- While transient (DKG can be retried), it causes consensus delays
- Exceeds Low severity ("remotely-exploitable denial of service in a node") because it affects the entire signing group, not just individual nodes

### Likelihood Explanation

**Required Attacker Capabilities:**

1. **Registered signer**: Attacker must be a valid signer with a registered signer_id in the configuration
2. **Valid signing key**: Must possess the private key corresponding to their signer_id's public key to create valid packet signatures
3. **Network access**: Ability to send messages to coordinator and other signers

**Attack Complexity:**

**Low** - The attack is trivial to execute:
1. Construct DkgPublicShares message with PolyCommitment containing Vec::with_capacity(10_000_000) points (can use arbitrary/invalid points since validation never happens)
2. Sign the packet with the attacker's private key
3. Send to coordinator and/or other signers during DKG phase

**Economic Feasibility:**

**High** - Attack requires minimal resources:
- Single malicious message from an insider signer
- No computational cost to attacker (victim pays the CPU/memory cost)
- Can be repeated every DKG round to maintain persistent DoS

**Detection Risk:**

**Low** - The attack appears as a legitimate DKG message:
- Properly signed by a valid signer
- Passes authentication checks
- Only becomes apparent when nodes become unresponsive
- No logging occurs before the exhaustion happens

**Estimated Probability of Success:**

**~100%** - The attack will succeed if:
- Attacker is a registered signer (insider threat model)
- No external message size limits exist at network layer
- Target nodes attempt to process the message

### Recommendation

**Primary Fix - Early Polynomial Size Validation:**

Add bounds checking immediately after deserialization, before any expensive operations:

```rust
// In src/net.rs, add validation in Packet::verify() or create a separate validate() method
impl Packet {
    pub fn validate_message_sizes(&self, max_poly_size: usize) -> Result<(), ValidationError> {
        match &self.msg {
            Message::DkgPublicShares(msg) => {
                for (_, comm) in &msg.comms {
                    if comm.poly.len() > max_poly_size {
                        return Err(ValidationError::PolySizeExceeded);
                    }
                }
            }
            // ... validate other message types
        }
        Ok(())
    }
}
```

Call this validation before packet.verify():

```rust
// In coordinator and signer process_message/process methods
packet.validate_message_sizes(threshold)?;
if self.config.verify_packet_sigs {
    if !packet.verify(&self.config.public_keys, &coordinator_public_key) {
        return Err(Error::InvalidPacketSignature);
    }
}
```

**Alternative Mitigations:**

1. **Deserializer limits**: Use serde annotations or custom deserializers to enforce maximum Vec sizes
2. **Network-layer limits**: Add maximum message size enforcement at the network transport layer
3. **Incremental hashing**: Modify hash implementation to fail-fast after detecting oversized vectors

**Testing Recommendations:**

1. Unit tests with polynomials of size: threshold-1, threshold, threshold+1, 10×threshold, 1000×threshold
2. Integration tests measuring memory/CPU usage with malicious payloads
3. Fuzz testing of DkgPublicShares deserialization with random sizes

**Deployment Considerations:**

- Set max_poly_size = threshold + small tolerance (e.g., threshold + 10)
- Add monitoring/alerting for message validation failures
- Consider rate-limiting DKG message processing per signer
- Document the maximum supported polynomial size

### Proof of Concept

**Exploitation Steps:**

1. **Construct malicious PolyCommitment:**
```rust
// Attacker (registered signer with signer_id and private key)
let mut malicious_poly = Vec::with_capacity(10_000_000);
// Fill with dummy points (don't need valid points since validation never happens)
for _ in 0..10_000_000 {
    malicious_poly.push(Point::identity()); // or Point::from(Scalar::one())
}

let malicious_comm = PolyCommitment {
    id: ID::new(&attacker_private_key, &Scalar::one(), &dkg_id.to_be_bytes(), rng),
    poly: malicious_poly,
};
```

2. **Create DkgPublicShares message:**
```rust
let malicious_msg = DkgPublicShares {
    dkg_id: current_dkg_id,
    signer_id: attacker_signer_id,
    comms: vec![(attacker_party_id, malicious_comm)],
    kex_public_key: attacker_kex_public_key,
};
```

3. **Sign and send packet:**
```rust
let packet = Packet {
    sig: malicious_msg.sign(&attacker_private_key).unwrap(),
    msg: Message::DkgPublicShares(malicious_msg),
};
// Send packet to coordinator and other signers
```

**Expected vs Actual Behavior:**

**Expected:** Message should be rejected immediately with "polynomial size exceeds threshold" error

**Actual:**
- Deserialization allocates ~640 MB for 10M points
- packet.verify() attempts to hash all 10M points
- Point compression takes ~0.1ms per point = ~16 minutes total CPU time
- Coordinator/signers become unresponsive
- Eventually timeout or OOM, but only after resources exhausted
- DKG round fails

**Reproduction Instructions:**

1. Set up WSTS coordinator and signers with threshold=10
2. Register malicious signer with valid credentials
3. During DKG round, send crafted message from malicious signer
4. Monitor coordinator/signer memory usage and CPU time
5. Observe that nodes become unresponsive before any validation error is logged
6. Confirm DKG round times out or fails with resource exhaustion

**Notes:**

The severity is Medium rather than Low because preventing DKG completion affects the entire signing group's ability to generate threshold signatures, which directly impacts consensus operations. This goes beyond simple node-level DoS to causing transient consensus failures in systems depending on WSTS for critical signing operations.

### Citations

**File:** src/common.rs (L26-33)
```rust
#[derive(Clone, Debug, Deserialize, Serialize, PartialEq)]
/// A commitment to a polynonial, with a Schnorr proof of ownership bound to the ID
pub struct PolyCommitment {
    /// The party ID with a schnorr proof
    pub id: ID,
    /// The public polynomial which commits to the secret polynomial
    pub poly: Vec<Point>,
}
```

**File:** src/common.rs (L319-321)
```rust
pub fn check_public_shares(poly_comm: &PolyCommitment, threshold: usize, ctx: &[u8]) -> bool {
    poly_comm.verify(ctx) && poly_comm.poly.len() == threshold
}
```

**File:** src/state_machine/coordinator/fire.rs (L218-225)
```rust
        if self.config.verify_packet_sigs {
            let Some(coordinator_public_key) = self.coordinator_public_key else {
                return Err(Error::MissingCoordinatorPublicKey);
            };
            if !packet.verify(&self.config.public_keys, &coordinator_public_key) {
                return Err(Error::InvalidPacketSignature);
            }
        }
```

**File:** src/state_machine/coordinator/fire.rs (L632-640)
```rust
                                for (party_id, comm) in &dkg_public_shares.comms {
                                    if !check_public_shares(
                                        comm,
                                        threshold,
                                        &self.current_dkg_id.to_be_bytes(),
                                    ) {
                                        bad_party_ids.push(party_id);
                                    }
                                }
```

**File:** src/state_machine/signer/mod.rs (L463-470)
```rust
        if self.verify_packet_sigs {
            let Some(coordinator_public_key) = self.coordinator_public_key else {
                return Err(Error::MissingCoordinatorPublicKey);
            };
            if !packet.verify(&self.public_keys, &coordinator_public_key) {
                return Err(Error::InvalidPacketSignature);
            }
        }
```

**File:** src/state_machine/signer/mod.rs (L556-562)
```rust
                    for (party_id, comm) in shares.comms.iter() {
                        if !check_public_shares(comm, threshold, &self.dkg_id.to_be_bytes()) {
                            bad_public_shares.insert(*signer_id);
                        } else {
                            self.commitments.insert(*party_id, comm.clone());
                        }
                    }
```

**File:** src/net.rs (L152-163)
```rust
impl Signable for DkgPublicShares {
    fn hash(&self, hasher: &mut Sha256) {
        hasher.update("DKG_PUBLIC_SHARES".as_bytes());
        hasher.update(self.dkg_id.to_be_bytes());
        hasher.update(self.signer_id.to_be_bytes());
        for (party_id, comm) in &self.comms {
            hasher.update(party_id.to_be_bytes());
            for a in &comm.poly {
                hasher.update(a.compress().as_bytes());
            }
        }
    }
```
