# Audit Report

## Title
FIRE Coordinator Aggregate Key Double-Counting via Duplicate Party IDs in DkgPublicShares

## Summary
The FIRE coordinator computes the aggregate public key by directly iterating over `DkgPublicShares.comms` vectors without deduplication, while signers use a HashMap that automatically deduplicates by `party_id`. A malicious signer can exploit this inconsistency by including duplicate `party_id` values in their `comms` vector, causing the coordinator to compute a different aggregate public key than the signers. This breaks all subsequent signature verification operations, resulting in a complete denial of service for the signing group.

## Finding Description

The vulnerability exists in the FIRE coordinator's `dkg_end_gathered()` function, which computes the aggregate public key by using `flat_map` to iterate over all `comms` vectors from all signers and sum the first coefficient of each polynomial commitment: [1](#0-0) 

This computation does not deduplicate `party_id` values. If a malicious signer sends a `DkgPublicShares` message with duplicate `party_id` entries in the `comms` vector, each duplicate will be counted separately.

The `DkgPublicShares` struct defines `comms` as a `Vec<(u32, PolyCommitment)>` with no inherent deduplication: [2](#0-1) 

The only validation performed on `DkgPublicShares` is that each `party_id` belongs to the sending signer: [3](#0-2) 

This validation checks ownership but does not detect or prevent duplicate `party_id` values within the same signer's `comms` vector.

In contrast, signers compute their group key by first inserting commitments into a `commitments` HashMap (which automatically deduplicates by `party_id`): [4](#0-3) 

Then computing the group key from this deduplicated HashMap: [5](#0-4) 

The FROST coordinator avoids this vulnerability by storing commitments in the `party_polynomials` HashMap first and then computing the aggregate key from that HashMap: [6](#0-5) 

Critically, the FIRE coordinator **also stores** commitments in the `party_polynomials` HashMap (which deduplicates), but then computes the aggregate key from the raw `comms` vectors instead: [7](#0-6) 

While the `set_key_and_party_polynomials()` function does check for duplicate party IDs, this function is only used when loading saved state, not during the normal DKG flow: [8](#0-7) 

**Attack Path:**

1. Malicious signer constructs `DkgPublicShares` with duplicate `party_id` values (e.g., `comms: [(5, comm_A), (5, comm_B)]` where they control party_id 5)
2. The coordinator's `gather_public_shares()` accepts the message without checking for duplicates
3. The signer validation passes because both entries have the same valid `party_id`
4. Signers insert both entries into their `commitments` HashMap, keeping only the last one
5. Signers compute `group_key = comm_B.poly[0]` (deduplicated)
6. FIRE coordinator computes `aggregate_public_key = comm_A.poly[0] + comm_B.poly[0]` (duplicates counted)
7. Result: `aggregate_public_key â‰  group_key`
8. All subsequent signature verification fails because the keys don't match

## Impact Explanation

This vulnerability causes a **complete denial of service** for all signing operations after DKG completion. When a malicious signer sends duplicate `party_id` values, the coordinator and signers derive different aggregate public keys. Any signatures generated by the signers will fail verification against the coordinator's aggregate key, and vice versa.

The impact severity is **Low** according to the provided scope definition: "Any remotely-exploitable denial of service in a node" or potentially "Any network denial of service impacting more than 10 percent of miners that does not shut down the network" if multiple signing groups are affected simultaneously.

The attack affects:
- All participants in the DKG round where the malicious message was sent
- All subsequent signing operations for that signing group
- Potentially dependent systems (e.g., Stacks blockchain operations) that rely on threshold signatures from the affected group

While this does not directly cause fund loss, it completely prevents the threshold signature scheme from functioning, blocking critical blockchain operations that require threshold signatures.

## Likelihood Explanation

The likelihood of exploitation is **very high** given that:

**Attacker Requirements:**
- Must be a registered signer with valid credentials (within protocol threat model)
- No cryptographic breaks required
- No special network positioning needed

**Attack Complexity:**
- Trivial to execute: construct a single `DkgPublicShares` message with duplicate `party_id` entries
- Example: If attacker controls party_ids [5, 6], they send `comms: [(5, C5), (6, C6), (5, C5')]`
- The message passes all validation checks (packet signature, party ownership)
- No timing attacks or race conditions required

**Detection Difficulty:**
- The DKG phase completes successfully with no errors or warnings
- The vulnerability only manifests during the signing phase when signatures fail verification
- Difficult to attribute to a specific malicious signer without detailed forensics
- Appears as a generic signature verification failure rather than obviously malicious input

**Success Rate:**
- 100% if the attacker is a registered signer
- No existing defenses prevent or detect this attack
- Guaranteed to cause signing operation failures

## Recommendation

Add validation to detect and reject duplicate `party_id` values in the `comms` vector. This can be implemented in the coordinator's `gather_public_shares()` function:

```rust
fn gather_public_shares(&mut self, packet: &Packet) -> Result<(), Error> {
    if let Message::DkgPublicShares(dkg_public_shares) = &packet.msg {
        // ... existing validation ...
        
        // Check for duplicate party_ids
        let mut seen_party_ids = HashSet::new();
        for (party_id, _) in &dkg_public_shares.comms {
            if !seen_party_ids.insert(*party_id) {
                warn!(
                    signer_id = %dkg_public_shares.signer_id,
                    party_id = %party_id,
                    "Duplicate party_id in DkgPublicShares"
                );
                return Err(Error::DuplicatePartyId);
            }
        }
        
        // ... rest of function ...
    }
    Ok(())
}
```

Alternatively, compute the aggregate key from the deduplicated `party_polynomials` HashMap (like the FROST coordinator does) instead of from the raw `comms` vectors:

```rust
fn dkg_end_gathered(&mut self) -> Result<(), Error> {
    // Cache the polynomials used in DKG for the aggregator
    for signer_id in self.dkg_private_shares.keys() {
        for (party_id, comm) in &self.dkg_public_shares[signer_id].comms {
            self.party_polynomials.insert(*party_id, comm.clone());
        }
    }

    // Calculate the aggregate public key from deduplicated party_polynomials
    let key = self
        .party_polynomials
        .iter()
        .fold(Point::default(), |s, (_, comm)| s + comm.poly[0]);

    info!("Aggregate public key: {key}");
    self.aggregate_public_key = Some(key);
    self.move_to(State::Idle)
}
```

## Proof of Concept

```rust
#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_duplicate_party_id_causes_key_mismatch() {
        // Setup coordinator and signer with threshold=2, 3 parties
        let mut coordinator = /* initialize FIRE coordinator */;
        let mut signer1 = /* initialize signer controlling party_id 1 */;
        
        // Signer creates DkgPublicShares with duplicate party_id
        let comm_a = PolyCommitment::new(/* ... */);
        let comm_b = PolyCommitment::new(/* ... */);
        
        let malicious_shares = DkgPublicShares {
            dkg_id: 1,
            signer_id: 1,
            comms: vec![
                (1, comm_a.clone()),  // First entry for party_id 1
                (1, comm_b.clone()),  // Duplicate entry for party_id 1
            ],
            kex_public_key: Point::default(),
        };
        
        // Coordinator processes the shares
        coordinator.process_dkg_public_shares(malicious_shares.clone());
        
        // Signer processes the shares (would store in HashMap, keeping only last)
        signer1.process_dkg_public_shares(malicious_shares.clone());
        
        // Complete DKG
        coordinator.dkg_end_gathered();
        signer1.compute_secrets(/* ... */);
        
        // Verify key mismatch
        let coordinator_key = coordinator.aggregate_public_key.unwrap();
        let signer_key = signer1.group_key;
        
        // Coordinator counts both: comm_a.poly[0] + comm_b.poly[0]
        // Signer keeps only last: comm_b.poly[0]
        assert_ne!(coordinator_key, signer_key, "Keys should mismatch due to duplicate counting");
    }
}
```

### Citations

**File:** src/state_machine/coordinator/fire.rs (L796-799)
```rust
        for signer_id in self.dkg_private_shares.keys() {
            for (party_id, comm) in &self.dkg_public_shares[signer_id].comms {
                self.party_polynomials.insert(*party_id, comm.clone());
            }
```

**File:** src/state_machine/coordinator/fire.rs (L803-807)
```rust
        let key = self
            .dkg_end_messages
            .keys()
            .flat_map(|signer_id| self.dkg_public_shares[signer_id].comms.clone())
            .fold(Point::default(), |s, (_, comm)| s + comm.poly[0]);
```

**File:** src/state_machine/coordinator/fire.rs (L1398-1401)
```rust
        let party_polynomials_len = party_polynomials.len();
        let party_polynomials = HashMap::from_iter(party_polynomials);
        if party_polynomials.len() != party_polynomials_len {
            return Err(Error::DuplicatePartyId);
```

**File:** src/net.rs (L141-147)
```rust
pub struct DkgPublicShares {
    /// DKG round ID
    pub dkg_id: u64,
    /// Signer ID
    pub signer_id: u32,
    /// List of (party_id, commitment)
    pub comms: Vec<(u32, PolyCommitment)>,
```

**File:** src/state_machine/signer/mod.rs (L556-561)
```rust
                    for (party_id, comm) in shares.comms.iter() {
                        if !check_public_shares(comm, threshold, &self.dkg_id.to_be_bytes()) {
                            bad_public_shares.insert(*signer_id);
                        } else {
                            self.commitments.insert(*party_id, comm.clone());
                        }
```

**File:** src/state_machine/signer/mod.rs (L993-1001)
```rust
        for (party_id, _) in &dkg_public_shares.comms {
            if !SignerType::validate_party_id(
                signer_id,
                *party_id,
                &self.public_keys.signer_key_ids,
            ) {
                warn!(%signer_id, %party_id, "signer sent polynomial commitment for wrong party");
                return Ok(vec![]);
            }
```

**File:** src/v2.rs (L135-140)
```rust
        for (i, comm) in public_shares.iter() {
            if !check_public_shares(comm, threshold, ctx) {
                bad_ids.push(*i);
            } else {
                self.group_key += comm.poly[0];
            }
```

**File:** src/state_machine/coordinator/frost.rs (L429-438)
```rust
            for (party_id, comm) in &dkg_public_shares.comms {
                self.party_polynomials.insert(*party_id, comm.clone());
            }
        }

        // Calculate the aggregate public key
        let key = self
            .party_polynomials
            .iter()
            .fold(Point::default(), |s, (_, comm)| s + comm.poly[0]);
```
