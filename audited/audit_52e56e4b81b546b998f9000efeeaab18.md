### Title
Key ID Duplication Bypass in Signer Initialization Breaks Lagrange Interpolation and Produces Invalid Signatures

### Summary
The `Signer::new()` function accepts duplicate key IDs without validation, causing signers to generate mathematically incorrect signature shares that include duplicate contributions from the same key ID. The coordinator's HashSet-based validation fails to detect this issue, resulting in invalid group signatures that fail verification and can prevent valid transactions from confirming.

### Finding Description

**Exact Code Location:**

The vulnerability exists in multiple locations across the codebase:

1. **State machine signer initialization** - No duplicate validation: [1](#0-0) 

The validation only checks if key IDs are within valid range [1, total_keys], but does NOT check for duplicates.

2. **v2 Party initialization** - Accepts duplicates as-is: [2](#0-1) 

At line 65, the function simply converts the key_ids slice to a vector without any deduplication: `key_ids: key_ids.to_vec()`.

3. **Signature share computation** - Double-counts duplicates: [3](#0-2) 

The signing loop iterates over `self.key_ids`, which may contain duplicates. For each key_id (including duplicates), it adds `c * private_keys[key_id] * lambda(key_id, key_ids)` to the signature share. If key_ids = [1, 2, 2], the contribution from key_id=2 is added TWICE, producing an incorrect signature share.

4. **Lagrange interpolation with duplicates**: [4](#0-3) 

If the signing key_ids set contains duplicates (e.g., [1, 2, 3, 2]), lambda coefficients are incorrectly computed. For lambda(1, [1,2,3,2]), the function multiplies by 2/(2-1) twice (once for each occurrence of 2), yielding lambda=6 instead of the correct lambda=3.

5. **Coordinator validation bypass**: [5](#0-4) 

The coordinator collects signature share key_ids into a HashSet (lines 1066-1071), which automatically deduplicates. It then compares against the configured signer_key_ids (also a HashSet). This means duplicates in the signature shares are silently deduplicated before comparison, allowing invalid signature shares to pass validation.

**Root Cause:**

The root cause is the absence of duplicate validation in the signer initialization path. The codebase assumes key_ids are unique but never enforces this invariant. Additionally, the coordinator's use of HashSets for validation inadvertently masks the problem by deduplicating before comparison.

**Why Existing Mitigations Fail:**

1. The `validate_key_id` function only checks range: [6](#0-5) 

2. The coordinator's validation uses HashSets which deduplicate: [7](#0-6) 

The `signer_key_ids` field is a `HashMap<u32, HashSet<u32>>`, causing automatic deduplication that hides the vulnerability.

### Impact Explanation

**Specific Harm:**
- **Invalid signatures produced**: When a signer is initialized with duplicate key_ids, it generates signature shares with mathematically incorrect values (double-counting contributions from duplicated keys).
- **Signature verification failure**: The aggregated signature fails cryptographic verification, causing the signing protocol to reject valid signing requests.
- **Transaction confirmation failure**: In a blockchain context, this prevents valid transactions from being confirmed, potentially halting the network.

**Quantified Impact:**
- If even one signer in a signing round has duplicate key_ids, the entire group signature becomes invalid
- With threshold T and a signer controlling duplicate key_ids [k, k], the effective weight becomes 2k instead of k, breaking the threshold calculation
- 100% failure rate for any signing operation involving an affected signer

**Who is Affected:**
- All participants in signing rounds involving a misconfigured signer
- Downstream systems relying on WSTS signatures (e.g., Stacks blockchain)
- End users whose transactions cannot be confirmed

**Severity Justification:**
This is **Critical** severity because it maps directly to: "Any network to shut down or otherwise not confirm new valid transactions for multiple blocks" and "Any confirmation of an invalid transaction, such as with an incorrect nonce" (in the inverse - valid transactions are rejected due to invalid signatures).

### Likelihood Explanation

**Required Attacker Capabilities:**
- **Configuration control**: Attacker must influence the initialization parameters passed to `Signer::new()`, OR
- **Coordinator control**: Attacker controls the coordinator and can manipulate the configured `signer_key_ids`, OR  
- **Signer initialization**: Attacker can initialize their own signer node with malicious configuration

**Attack Complexity:**
- **Low**: Simply pass duplicate values in the key_ids array during initialization
- No cryptographic operations required
- No timing or race conditions needed
- Single point of exploitation (initialization)

**Economic Feasibility:**
- **High**: Minimal cost to exploit if attacker can influence configuration
- In a permissioned setting, requires being an authorized signer
- In a permissionless setting, requires ability to join as a signer

**Detection Risk:**
- **Low-Medium**: The issue causes signature verification failures, making it detectable
- However, it appears as a "normal" signing failure, making root cause diagnosis difficult
- No obvious indicators that duplicate key_ids are the cause

**Estimated Probability:**
- **High** in misconfiguration scenarios (accidental duplicates during setup)
- **Medium** for deliberate attacks (requires some level of access)
- **Very High** impact if exploited (complete signing failure)

### Recommendation

**Immediate Fix:**

Add duplicate validation in the state machine signer initialization:

```rust
// In src/state_machine/signer/mod.rs, after line 312:
let key_ids_set: HashSet<u32> = key_ids.iter().copied().collect();
if key_ids_set.len() != key_ids.len() {
    return Err(Error::Config(ConfigError::DuplicateKeyIds));
}
```

**Additional Mitigations:**

1. Add duplicate checks in v2::Party::new():
```rust
// In src/v2.rs:62, before line 63:
let key_ids_set: HashSet<u32> = key_ids.iter().copied().collect();
assert_eq!(key_ids_set.len(), key_ids.len(), "key_ids must not contain duplicates");
```

2. Change internal storage to use HashSet to enforce uniqueness:
```rust
// In src/v2.rs:29:
pub key_ids: HashSet<u32>,  // instead of Vec<u32>
```

3. Add coordinator validation that checks lengths before HashSet comparison:
```rust
// In src/state_machine/coordinator/fire.rs:1073, before comparison:
let total_key_ids: usize = sig_share_response.signature_shares
    .iter()
    .map(|s| s.key_ids.len())
    .sum();
if total_key_ids != sig_share_response_key_ids.len() {
    return Err(Error::DuplicateKeyIDsInResponse(sig_share_response.signer_id));
}
```

**Testing Recommendations:**
- Add unit test initializing Signer with duplicate key_ids, expecting error
- Add integration test verifying signing fails with duplicate key_ids
- Add property test generating random key_ids with duplicates

**Deployment Considerations:**
- This is a breaking change for any existing configurations with duplicate key_ids
- Audit all existing signer configurations before deployment
- Provide clear error messages to help operators identify and fix misconfigurations

### Proof of Concept

**Exploitation Algorithm:**

1. Initialize a v2::Party with duplicate key_ids:
```
key_ids = [1, 2, 2]
party = Party::new(party_id=0, key_ids=[1,2,2], num_parties=3, num_keys=3, threshold=2, rng)
```

2. Run DKG to derive private keys:
```
During compute_secrets():
    - private_keys HashMap receives: {1: secret1, 2: secret2}
    - Only 2 entries despite 3 key_ids (HashMap overwrites duplicate key 2)
```

3. Generate signature share:
```
During sign_with_tweak():
    - Loop iteration 1: key_id=1, cx += c * private_keys[1] * lambda(1, [1,2,2])
    - Loop iteration 2: key_id=2, cx += c * private_keys[2] * lambda(2, [1,2,2])  
    - Loop iteration 3: key_id=2 AGAIN, cx += c * private_keys[2] * lambda(2, [1,2,2])
    - Result: cx includes DOUBLE contribution from key_id=2
```

4. Coordinator validation passes:
```
sig_share_response_key_ids = HashSet::from([1, 2, 2]) = {1, 2}
configured_signer_key_ids = {1, 2}
Comparison: {1, 2} == {1, 2} âœ“ PASSES (incorrectly)
```

5. Aggregator produces invalid signature:
```
Aggregator sums all z_i values (including the invalid one with double contribution)
Result: signature verification FAILS
```

**Expected vs Actual Behavior:**

**Expected:** `Signer::new()` should reject duplicate key_ids with an error during initialization.

**Actual:** `Signer::new()` accepts duplicate key_ids, stores them in the Vec, and during signing produces mathematically incorrect signature shares that cause the aggregated signature to fail verification.

**Reproduction Instructions:**

1. Create a test in `src/v2.rs`:
```rust
#[test]
#[should_panic]  // Currently DOES NOT panic - this is the bug
fn test_duplicate_key_ids_rejected() {
    let mut rng = create_rng();
    let duplicate_key_ids = vec![1, 2, 2];
    Party::new(0, &duplicate_key_ids, 3, 3, 2, &mut rng);
}
```

2. Run the test: `cargo test test_duplicate_key_ids_rejected`

3. Observe that it does NOT panic (vulnerability confirmed)

4. Run a full signing round with a signer having duplicate key_ids and observe signature verification failure

### Citations

**File:** src/state_machine/signer/mod.rs (L308-312)
```rust
        for key_id in &key_ids {
            if !validate_key_id(*key_id, total_keys) {
                return Err(Error::Config(ConfigError::InvalidKeyId(*key_id)));
            }
        }
```

**File:** src/v2.rs (L55-74)
```rust
    pub fn new<RNG: RngCore + CryptoRng>(
        party_id: u32,
        key_ids: &[u32],
        num_parties: u32,
        num_keys: u32,
        threshold: u32,
        rng: &mut RNG,
    ) -> Self {
        Self {
            party_id,
            key_ids: key_ids.to_vec(),
            num_keys,
            num_parties,
            threshold,
            f: Some(VSS::random_poly(threshold - 1, rng)),
            private_keys: Default::default(),
            group_key: Point::zero(),
            nonce: Nonce::zero(),
        }
    }
```

**File:** src/v2.rs (L262-265)
```rust
        let mut cx = Scalar::zero();
        for key_id in self.key_ids.iter() {
            cx += c * &self.private_keys[key_id] * compute::lambda(*key_id, key_ids);
        }
```

**File:** src/compute.rs (L70-80)
```rust
pub fn lambda(i: u32, key_ids: &[u32]) -> Scalar {
    let mut lambda = Scalar::one();
    let i_scalar = id(i);
    for j in key_ids {
        if i != *j {
            let j_scalar = id(*j);
            lambda *= j_scalar / (j_scalar - i_scalar);
        }
    }
    lambda
}
```

**File:** src/state_machine/coordinator/fire.rs (L1066-1076)
```rust
        let mut sig_share_response_key_ids = HashSet::new();
        for sig_share in &sig_share_response.signature_shares {
            for key_id in &sig_share.key_ids {
                sig_share_response_key_ids.insert(*key_id);
            }
        }

        if *signer_key_ids != sig_share_response_key_ids {
            warn!(signer_id = %sig_share_response.signer_id, "SignatureShareResponse key_ids didn't match config");
            return Err(Error::BadKeyIDsForSigner(sig_share_response.signer_id));
        }
```

**File:** src/common.rs (L314-316)
```rust
pub fn validate_key_id(key_id: u32, num_keys: u32) -> bool {
    key_id > 0 && key_id <= num_keys
}
```

**File:** src/state_machine/mod.rs (L101-101)
```rust
    pub signer_key_ids: HashMap<u32, HashSet<u32>>,
```
