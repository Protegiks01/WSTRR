### Title
Coordinator Indefinite Hang Due to None Timeout Configuration Enabling Denial-of-Service

### Summary
When all timeout fields in the coordinator configuration are set to None, both FROST and FIRE coordinators hang indefinitely waiting for responses from signers. The default configuration uses None for all timeouts, enabling trivial denial-of-service attacks where a single malicious or unresponsive signer can permanently block DKG or signing rounds by simply not sending expected messages.

### Finding Description

**Exact Code Locations:**

The Config struct defines five optional timeout fields that default to None: [1](#0-0) 

The default constructor Config::new() explicitly sets all timeouts to None: [2](#0-1) 

**FROST Coordinator - No Timeout Handling:**

The FROST coordinator's process() method directly calls process_message() without any timeout checks: [3](#0-2) 

In gather states like DkgPublicGather, the coordinator waits for ids_to_await to become empty before advancing: [4](#0-3) 

Similar blocking occurs in DkgPrivateGather, DkgEndGather, NonceGather, and SigShareGather states.

**FIRE Coordinator - Conditional Timeout Handling:**

The FIRE coordinator's process() method calls process_timeout() before processing messages: [5](#0-4) 

However, process_timeout() only enforces timeouts when they are Some(Duration). For DkgPublicGather state: [6](#0-5) 

The pattern `if let Some(timeout) = self.config.dkg_public_timeout` means when the timeout is None, no timeout checking occurs. Similar conditional checks exist for all other timeout fields (lines 107, 135, 151, 175).

**Root Cause:**

Timeouts are designed as optional with None as a valid value. When None, coordinators enter gather states and wait indefinitely for all expected signers to respond. If any signer fails to respond (maliciously or due to network issues), the coordinator remains blocked in that state permanently. The coordinator checks completion conditions like `ids_to_await.is_empty()` or `dkg_wait_signer_ids.is_empty()`, which can never be satisfied if a signer doesn't respond and no timeout is configured.

**Why Existing Mitigations Fail:**

The Config::with_timeouts() constructor exists to set timeouts, but the default Config::new() uses None. Test infrastructure also defaults to None: [7](#0-6) 

No warnings or documentation indicate that None timeouts create a security vulnerability.

### Impact Explanation

**Specific Harm:**
- **DKG Phase**: If coordinator hangs during DkgPublicGather, DkgPrivateGather, or DkgEndGather, the DKG round cannot complete. No aggregate public key is generated, making the entire signing system non-operational.
- **Signing Phase**: If coordinator hangs during NonceGather or SigShareGather, signature shares cannot be collected and no valid signature is produced. Transactions requiring these signatures cannot be confirmed.

**Quantified Impact:**
A single malicious signer out of N total signers can block the entire coordinator indefinitely. With default configuration, the coordinator requires responses from all N signers. One non-responsive signer halts all operations permanently until manual intervention (restart/reconfiguration).

**Who Is Affected:**
All users and systems depending on the coordinator for signature generation. In a blockchain context, this prevents transaction confirmation and could halt block production if the coordinator is critical infrastructure.

**Severity Justification:**
This maps to **"Any transient consensus failures"** (Medium severity per scope definition). The coordinator's inability to complete DKG or produce signatures causes consensus disruption. While potentially recoverable through restart or configuration changes, the ease of exploitation and impact on availability justify Medium severity. In worst-case scenarios where the coordinator is essential for block production, this could approach Critical severity ("not confirm new valid transactions for multiple blocks").

### Likelihood Explanation

**Required Attacker Capabilities:**
- Must be a registered signer in the system
- Requires no cryptographic secrets beyond legitimate signer credentials
- No special network position required
- No knowledge of protocol internals needed

**Attack Complexity:**
TRIVIAL - The attacker simply does not send expected messages (DkgPublicShares, DkgPrivateShares, DkgEnd, NonceResponse, or SignatureShareResponse). No active exploitation code required; passive non-participation is sufficient.

**Attack Steps:**
1. Attacker is configured as one of N signers
2. Coordinator starts DKG or signing round
3. Attacker receives coordinator's request message
4. Attacker ignores the request and sends no response
5. Coordinator waits indefinitely for attacker's response
6. All legitimate operations blocked until manual intervention

**Economic Feasibility:**
Zero cost to execute. No computational resources, network bandwidth, or time investment required beyond initial signer registration.

**Detection Risk:**
Low for attacker. The coordinator cannot distinguish malicious non-response from legitimate network issues or node failures. The attacker appears as an offline or unresponsive node.

**Probability of Success:**
Nearly 100%. With default None timeout configuration, any single signer can block the coordinator indefinitely. No defensive mechanisms exist when timeouts are disabled.

### Recommendation

**Immediate Fixes:**

1. **Enforce Non-None Timeouts**: Modify Config::new() to include reasonable default timeouts (e.g., 30-60 seconds for DKG phases, 10-30 seconds for signing):
   - dkg_public_timeout: Some(Duration::from_secs(30))
   - dkg_private_timeout: Some(Duration::from_secs(30))
   - dkg_end_timeout: Some(Duration::from_secs(30))
   - nonce_timeout: Some(Duration::from_secs(15))
   - sign_timeout: Some(Duration::from_secs(15))

2. **Implement FROST Timeout Handling**: Add timeout checking to FROST coordinator's process() method similar to FIRE coordinator's process_timeout() pattern.

3. **Make Timeouts Required**: Consider changing timeout fields from `Option<Duration>` to `Duration` in Config struct, eliminating the None case entirely.

**Alternative Mitigations:**

- Add configuration validation that warns or errors when timeouts are None
- Document security implications of None timeouts prominently in Config documentation
- Implement watchdog timers at a higher application layer
- Add metrics/alerts for coordinators stuck in gather states

**Testing Recommendations:**

- Add integration tests where one signer intentionally doesn't respond with timeouts set to Some(Duration) - verify coordinator times out gracefully
- Add tests with None timeouts to demonstrate vulnerability
- Test timeout edge cases (exactly at timeout boundary)
- Verify timeout behavior across all gather states

**Deployment Considerations:**

- Existing deployments using Config::new() are vulnerable and should be patched immediately
- Timeout values should be tuned based on expected network latency and signer responsiveness
- Consider making timeouts configurable per-deployment while enforcing minimum values

### Proof of Concept

**Setup:**
1. Create coordinator configuration using Config::new() (all timeouts None)
2. Initialize coordinator with this configuration
3. Register N signers (e.g., N=5)

**Exploitation - DKG Phase:**
1. Coordinator calls start_dkg_round(), enters DkgPublicGather state
2. Coordinator sends DkgBegin message to all 5 signers
3. Coordinator initializes ids_to_await = {0, 1, 2, 3, 4}
4. Signers 0, 1, 2, 3 send DkgPublicShares responses
5. Coordinator processes these 4 responses, ids_to_await = {4}
6. Attacker (signer 4) never sends DkgPublicShares
7. Coordinator remains in DkgPublicGather state indefinitely
8. Coordinator never advances to DkgPrivateDistribute state
9. DKG cannot complete, no aggregate public key generated

**Exploitation - Signing Phase:**
1. Assume DKG completed successfully (all signers cooperative)
2. Coordinator calls start_signing_round(), enters NonceGather state
3. Coordinator sends NonceRequest to all 5 signers
4. Signers 0, 1, 2, 3 send NonceResponse
5. Attacker (signer 4) never sends NonceResponse
6. Coordinator remains in NonceGather state indefinitely
7. Signature share collection never begins
8. No signature produced, transaction cannot be confirmed

**Expected vs Actual Behavior:**

Expected with timeouts: After timeout period, coordinator detects non-responsive signer(s), returns timeout error (DkgPublicTimeout, NonceTimeout, etc.), allows retry or signer exclusion.

Actual with None timeouts: Coordinator hangs indefinitely in gather state, never advances, requires manual intervention (kill/restart process, reconfigure timeouts).

**Reproduction:**
Use the test setup function which defaults to None timeouts, have one signer in the test harness skip sending any response message. Observe coordinator state remains stuck. Add timeout to configuration, observe coordinator properly times out and returns error result.

### Citations

**File:** src/state_machine/coordinator/mod.rs (L144-153)
```rust
    /// timeout to gather DkgPublicShares messages
    pub dkg_public_timeout: Option<Duration>,
    /// timeout to gather DkgPrivateShares messages
    pub dkg_private_timeout: Option<Duration>,
    /// timeout to gather DkgEnd messages
    pub dkg_end_timeout: Option<Duration>,
    /// timeout to gather nonces
    pub nonce_timeout: Option<Duration>,
    /// timeout to gather signature shares
    pub sign_timeout: Option<Duration>,
```

**File:** src/state_machine/coordinator/mod.rs (L179-200)
```rust
    /// Create a new config object with no timeouts
    pub fn new(
        num_signers: u32,
        num_keys: u32,
        threshold: u32,
        message_private_key: Scalar,
    ) -> Self {
        Config {
            num_signers,
            num_keys,
            threshold,
            dkg_threshold: num_keys,
            message_private_key,
            dkg_public_timeout: None,
            dkg_private_timeout: None,
            dkg_end_timeout: None,
            nonce_timeout: None,
            sign_timeout: None,
            public_keys: Default::default(),
            verify_packet_sigs: true,
        }
    }
```

**File:** src/state_machine/coordinator/mod.rs (L548-561)
```rust
    pub fn setup<Coordinator: CoordinatorTrait, SignerType: SignerTrait>(
        num_signers: u32,
        keys_per_signer: u32,
    ) -> (Vec<Coordinator>, Vec<Signer<SignerType>>) {
        setup_with_timeouts::<Coordinator, SignerType>(
            num_signers,
            keys_per_signer,
            None,
            None,
            None,
            None,
            None,
        )
    }
```

**File:** src/state_machine/coordinator/frost.rs (L290-334)
```rust
    fn gather_public_shares(&mut self, packet: &Packet) -> Result<(), Error> {
        if let Message::DkgPublicShares(dkg_public_shares) = &packet.msg {
            if dkg_public_shares.dkg_id != self.current_dkg_id {
                return Err(Error::BadDkgId(
                    dkg_public_shares.dkg_id,
                    self.current_dkg_id,
                ));
            }

            // check that the signer_id exists in the config
            let signer_public_keys = &self.config.public_keys.signers;
            if !signer_public_keys.contains_key(&dkg_public_shares.signer_id) {
                warn!(signer_id = %dkg_public_shares.signer_id, "No public key in config");
                return Ok(());
            };

            let have_shares = self
                .dkg_public_shares
                .contains_key(&dkg_public_shares.signer_id);

            if have_shares {
                info!(signer_id = %dkg_public_shares.signer_id, "received duplicate DkgPublicShares");
                return Ok(());
            }

            self.ids_to_await.remove(&dkg_public_shares.signer_id);

            self.dkg_public_shares
                .insert(dkg_public_shares.signer_id, dkg_public_shares.clone());
            for (party_id, comm) in &dkg_public_shares.comms {
                self.party_polynomials.insert(*party_id, comm.clone());
            }

            debug!(
                dkg_id = %dkg_public_shares.dkg_id,
                signer_id = %dkg_public_shares.signer_id,
                "DkgPublicShares received"
            );
        }

        if self.ids_to_await.is_empty() {
            self.move_to(State::DkgPrivateDistribute)?;
        }
        Ok(())
    }
```

**File:** src/state_machine/coordinator/frost.rs (L929-934)
```rust
    fn process(
        &mut self,
        packet: &Packet,
    ) -> Result<(Option<Packet>, Option<OperationResult>), Error> {
        self.process_message(packet)
    }
```

**File:** src/state_machine/coordinator/fire.rs (L77-103)
```rust
            State::DkgPublicGather => {
                if let Some(start) = self.dkg_public_start {
                    if let Some(timeout) = self.config.dkg_public_timeout {
                        if now.duration_since(start) > timeout {
                            // check dkg_threshold to determine if we can continue
                            let dkg_size = self.compute_dkg_public_size()?;

                            if self.config.dkg_threshold > dkg_size {
                                error!("Timeout gathering DkgPublicShares for dkg round {} signing round {} iteration {}, dkg_threshold not met ({dkg_size}/{}), unable to continue", self.current_dkg_id, self.current_sign_id, self.current_sign_iter_id, self.config.dkg_threshold);
                                let wait = self.dkg_wait_signer_ids.iter().copied().collect();
                                return Ok((
                                    None,
                                    Some(OperationResult::DkgError(DkgError::DkgPublicTimeout(
                                        wait,
                                    ))),
                                ));
                            } else {
                                // we hit the timeout but met the threshold, continue
                                warn!("Timeout gathering DkgPublicShares for dkg round {} signing round {} iteration {}, dkg_threshold was met ({dkg_size}/{}), ", self.current_dkg_id, self.current_sign_id, self.current_sign_iter_id, self.config.dkg_threshold);
                                self.public_shares_gathered()?;
                                let packet = self.start_private_shares()?;
                                return Ok((Some(packet), None));
                            }
                        }
                    }
                }
            }
```

**File:** src/state_machine/coordinator/fire.rs (L1444-1454)
```rust
    fn process(
        &mut self,
        packet: &Packet,
    ) -> Result<(Option<Packet>, Option<OperationResult>), Error> {
        let (outbound_packet, operation_result) = self.process_timeout()?;
        if outbound_packet.is_some() || operation_result.is_some() {
            return Ok((outbound_packet, operation_result));
        }

        self.process_message(packet)
    }
```
