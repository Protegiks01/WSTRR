### Title
Duplicate Key IDs in Signer Initialization Cause Incorrect Lagrange Interpolation and Signature Failures

### Summary
The `Signer::new()` function in both v1 and v2 implementations does not validate that the `key_ids` parameter contains unique values. Duplicate key IDs cause multiple issues: during DKG, only the last duplicate's shares are retained via HashMap overwrites; during signing, duplicate key IDs in the aggregated key set produce mathematically incorrect Lagrange interpolation coefficients, resulting in invalid signatures that fail verification. This violates the explicit security invariant that "Lagrange interpolation must use the correct key set with no duplicates."

### Finding Description

**Root Cause**: The state machine's `Signer::new()` function validates that each key_id is within valid range (1 to total_keys) but does not check for duplicates within the `key_ids` Vec parameter. [1](#0-0) 

In v1, each key_id creates a separate `Party` object, so duplicate key_ids result in multiple parties with the same ID: [2](#0-1) 

When `get_shares()` collects shares from all parties into a HashMap keyed by party.id, duplicate IDs cause the later party's shares to overwrite earlier ones: [3](#0-2) 

However, `get_key_ids()` returns ALL party IDs including duplicates: [4](#0-3) 

This Vec with duplicates propagates into `NonceResponse.key_ids`: [5](#0-4) 

The coordinator collects all key_ids from nonce responses via `flat_map`, preserving duplicates: [6](#0-5) 

**Critical Failure**: This aggregated `key_ids` Vec with duplicates is passed to `lambda()` for Lagrange interpolation. When duplicates exist, lambda computes INCORRECT coefficients. For example, `lambda(1, [1,2,2,3])` multiplies the factor `2/(2-1)` twice, yielding 6 instead of the correct value 3 for `lambda(1, [1,2,3])`: [7](#0-6) 

**Why Existing Mitigations Fail**: The coordinator validates that `NonceResponse.key_ids` matches the configured `signer_key_ids`, but both are converted to HashSet for comparison, which collapses duplicates and allows [1,2,2,3] to match {1,2,3}: [8](#0-7) 

The same issue exists in v2 where a single Party can control multiple key_ids: [9](#0-8) 

### Impact Explanation

**Specific Harm**: Incorrect Lagrange coefficients cause signature aggregation to produce invalid signatures that fail verification. All signing operations involving the misconfigured signer will fail.

**Quantification**: If even one signer is initialized with duplicate key_ids, any signing round that includes that signer will produce an invalid signature, effectively causing a denial of service for signing operations. In a threshold signature scheme where t-of-n signatures are required, if one signer is misconfigured, the coordinator must exclude them and ensure t signers remain available without them.

**Who is Affected**: Any signing round that includes a signer with duplicate key_ids will fail. If the system relies on specific signers for liveness (e.g., fewer than threshold+1 signers available), this could prevent transaction confirmation entirely.

**Severity**: **Low** - Maps to "Any remotely-exploitable denial of service in a node." While this requires control over configuration parameters rather than direct network exploitation, the misconfiguration causes complete signing failures. If a significant portion of signers are misconfigured, this could escalate to "network denial of service impacting more than 10 percent of miners."

### Likelihood Explanation

**Required Attacker Capabilities**: Attacker must be able to influence the `key_ids` Vec parameter passed to `state_machine::Signer::new()` during node initialization. This typically comes from:
1. Configuration files that define signer key_id assignments
2. Initialization scripts or deployment automation
3. Coordinator messages that specify key_id distributions (if dynamically assigned)

**Attack Complexity**: Low to Medium. If configuration is user-editable or comes from untrusted sources, an attacker could inject duplicate key_ids. However, the `PublicKeys` structure stores `signer_key_ids` as `HashMap<u32, HashSet<u32>>`, which naturally deduplicates. The vulnerability only manifests if the Vec is constructed separately from this HashSet or if the conversion doesn't occur.

**Economic Feasibility**: High. No economic cost beyond gaining access to modify configuration.

**Detection Risk**: Low. The misconfiguration is not caught by existing validation, and the symptoms (signature verification failures) don't clearly indicate duplicate key_ids as the root cause. Logging shows key_ids arrays but doesn't flag duplicates.

**Estimated Probability**: Medium. More likely to occur through configuration error (copy-paste mistakes, incorrect scripts) than deliberate attack, but the complete lack of validation makes it easy to introduce accidentally.

### Recommendation

**Primary Fix**: Add duplicate validation in `state_machine::Signer::new()` before passing `key_ids` to the underlying signer implementation:

```rust
// After line 312 in src/state_machine/signer/mod.rs
let mut seen = HashSet::new();
for key_id in &key_ids {
    if !seen.insert(*key_id) {
        return Err(Error::Config(ConfigError::DuplicateKeyId(*key_id)));
    }
}
```

Add new error variant:
```rust
// In ConfigError enum
#[error("Duplicate key ID {0}")]
DuplicateKeyId(u32),
```

**Alternative Mitigation**: Force conversion through HashSet when extracting key_ids from `PublicKeys`:

```rust
// When building key_ids from config
let key_ids: Vec<u32> = config.public_keys.signer_key_ids
    .get(&signer_id)
    .ok_or(Error::MissingKeyIds)?
    .iter()
    .cloned()
    .collect();
```

This ensures duplicates are removed at the source.

**Coordinator Enhancement**: Fix the validation logic to detect length mismatches:

```rust
// In coordinator validation
if nonce_response.key_ids.len() != signer_key_ids.len() 
    || *signer_key_ids != nonce_response_key_ids {
    warn!("Key IDs mismatch or contains duplicates");
    return Ok(());
}
```

**Testing Recommendations**:
1. Add unit test with duplicate key_ids: `Signer::new(0, &[1, 2, 2, 3], ...)` should return error
2. Add integration test showing signature failure with duplicates
3. Add test verifying lambda produces different values with/without duplicates
4. Verify DKG detects the issue before reaching signing phase

**Deployment Considerations**: Add configuration validation tool that checks for duplicate key_ids across all signer configurations before deployment. Include clear error messages identifying which signer and which key_id is duplicated.

### Proof of Concept

**Exploitation Steps**:

1. Initialize a v1 or v2 Signer with duplicate key_ids:
   ```rust
   let signer = v1::Signer::new(
       0,                    // signer_id
       &[1, 2, 2, 3],       // key_ids with duplicate 2
       10,                   // num_keys
       7,                    // threshold
       &mut rng
   );
   ```

2. Complete DKG (will succeed but only use one of the duplicate Party{id:2}):
   ```rust
   let polys = test_helpers::dkg(&mut signers, &mut rng).unwrap();
   ```

3. Attempt signing operation:
   ```rust
   let key_ids = signer.get_key_ids();  // Returns [1, 2, 2, 3]
   let nonces = signer.gen_nonces(&secret_key, &mut rng);
   let shares = signer.sign(&msg, &signer_ids, &key_ids, &nonces);
   ```

4. Aggregate signature (will fail):
   ```rust
   let result = aggregator.sign(&msg, &nonces, &shares, &key_ids);
   // Fails verification due to incorrect lambda(1, [1,2,2,3])
   ```

**Expected vs Actual Behavior**:
- **Expected**: `Signer::new()` should reject `key_ids` = `[1, 2, 2, 3]` with a duplicate validation error
- **Actual**: Initialization succeeds, but `lambda(1, [1,2,2,3])` computes as 6 instead of 3, causing signature verification to fail

**Parameter Values Demonstrating Impact**:
- `lambda(1, [1,2,2,3])` = `1 * (2/(2-1)) * (2/(2-1)) * (3/(3-1))` = `1 * 2 * 2 * 1.5` = `6`
- `lambda(1, [1,2,3])` = `1 * (2/(2-1)) * (3/(3-1))` = `1 * 2 * 1.5` = `3`

This factor-of-2 error propagates through the signature aggregation, causing `z * G â‰  R + c*Y`, failing the verification equation.

### Notes

This vulnerability exists in both v1 and v2 implementations with slightly different manifestations but the same root cause and impact. The issue violates two explicit security invariants stated in the protocol specification: "Lagrange interpolation must use the correct key set with no duplicates" and "Threshold and key ID bounds must be enforced; no duplicates or out-of-range IDs."

### Citations

**File:** src/state_machine/signer/mod.rs (L308-312)
```rust
        for key_id in &key_ids {
            if !validate_key_id(*key_id, total_keys) {
                return Err(Error::Config(ConfigError::InvalidKeyId(*key_id)));
            }
        }
```

**File:** src/state_machine/signer/mod.rs (L730-740)
```rust
        let key_ids = self.signer.get_key_ids();
        let nonces = self.signer.gen_nonces(&self.network_private_key, rng);

        let response = NonceResponse {
            dkg_id: nonce_request.dkg_id,
            sign_id: nonce_request.sign_id,
            sign_iter_id: nonce_request.sign_iter_id,
            signer_id,
            key_ids,
            nonces,
            message: nonce_request.message.clone(),
```

**File:** src/v1.rs (L537-547)
```rust
        let parties = key_ids
            .iter()
            .map(|id| Party::new(*id, num_keys, threshold, rng))
            .collect();
        Signer {
            id,
            num_keys,
            threshold,
            group_key: Point::zero(),
            parties,
        }
```

**File:** src/v1.rs (L605-607)
```rust
    fn get_key_ids(&self) -> Vec<u32> {
        self.parties.iter().map(|p| p.id).collect()
    }
```

**File:** src/v1.rs (L640-646)
```rust
    fn get_shares(&self) -> HashMap<u32, HashMap<u32, Scalar>> {
        let mut shares = HashMap::new();
        for party in &self.parties {
            shares.insert(party.id, party.get_shares());
        }
        shares
    }
```

**File:** src/state_machine/coordinator/fire.rs (L881-889)
```rust
            let nonce_response_key_ids = nonce_response
                .key_ids
                .iter()
                .cloned()
                .collect::<HashSet<u32>>();
            if *signer_key_ids != nonce_response_key_ids {
                warn!(signer_id = %nonce_response.signer_id, "Nonce response key_ids didn't match config");
                return Ok(());
            }
```

**File:** src/state_machine/coordinator/fire.rs (L1126-1129)
```rust
            let key_ids = nonce_responses
                .iter()
                .flat_map(|nr| nr.key_ids.clone())
                .collect::<Vec<u32>>();
```

**File:** src/compute.rs (L69-80)
```rust
/// Compute the Lagrange interpolation value
pub fn lambda(i: u32, key_ids: &[u32]) -> Scalar {
    let mut lambda = Scalar::one();
    let i_scalar = id(i);
    for j in key_ids {
        if i != *j {
            let j_scalar = id(*j);
            lambda *= j_scalar / (j_scalar - i_scalar);
        }
    }
    lambda
}
```

**File:** src/v2.rs (L563-565)
```rust
    fn get_key_ids(&self) -> Vec<u32> {
        self.key_ids.clone()
    }
```
