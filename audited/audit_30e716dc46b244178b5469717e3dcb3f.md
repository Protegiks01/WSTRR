### Title
Coordinator Configuration Validation Gap Allows `num_signers > num_keys` Leading to DKG Deadlock

### Summary
The Coordinator accepts configurations where `num_signers > num_keys` without validation, while Signers reject such configurations. This asymmetry causes the Coordinator to wait indefinitely for signer responses that cannot exist, resulting in DKG deadlock without timeouts or transient consensus failures with timeouts.

### Finding Description

The `Coordinator::new()` method in both FIRE and FROST implementations accepts any `Config` without validating the relationship between `num_signers` and `num_keys`: [1](#0-0) [2](#0-1) 

In contrast, `Signer::new()` explicitly validates this relationship and rejects invalid configurations: [3](#0-2) 

The `Config` constructors also lack validation: [4](#0-3) [5](#0-4) 

**Root Cause:** During DKG initialization, the Coordinator sets `dkg_wait_signer_ids` to include ALL signer IDs from 0 to `num_signers-1`: [6](#0-5) 

When `num_signers > num_keys`, not all signer IDs can have corresponding entries in `config.public_keys.signers` (since each signer needs at least one key). The Coordinator checks incoming messages against `config.public_keys.signers` and ignores messages from unlisted signers: [7](#0-6) 

However, the Coordinator only proceeds when `dkg_wait_signer_ids.is_empty()`: [8](#0-7) 

This creates a deadlock where the Coordinator waits for signers that cannot exist.

**Why Existing Mitigations Fail:** Timeouts provide partial mitigation by allowing DKG to proceed if `dkg_threshold` is met: [9](#0-8) 

However, if no timeout is configured (`dkg_public_timeout = None`), the Coordinator waits forever. Even with timeouts, this causes confusion and may prevent DKG completion if the threshold cannot be met by the available keys.

### Impact Explanation

**Specific Harm:**
1. **Without Timeouts:** Permanent DKG deadlock. The Coordinator enters `DkgPublicGather` state and never advances, blocking all subsequent operations.
2. **With Timeouts:** Transient DKG failures if `dkg_threshold` exceeds the number of keys from signers that can exist. Even if threshold is met, this causes unnecessary delays and error handling.

**Quantification:** With `num_signers=10` and `num_keys=5` (assuming 1 key per signer):
- Coordinator waits for 10 signers (IDs 0-9)
- Only 5 signers can exist (at most)
- 5 signer IDs remain in `dkg_wait_signer_ids` indefinitely
- `compute_dkg_public_size()` returns at most 5 keys [10](#0-9) 

If `dkg_threshold > 5`, DKG fails. If `dkg_threshold <= 5`, DKG proceeds after timeout but causes unnecessary delay.

**Who is Affected:** Any deployment using Coordinators with misconfigured `num_signers > num_keys`, particularly those without timeouts.

**Severity Justification:** Medium - This causes "transient consensus failures" as defined in the protocol scope. DKG is required for establishing the aggregate public key, and DKG failure prevents signature generation, causing consensus delays or failures.

### Likelihood Explanation

**Required Capabilities:**
- Ability to configure and instantiate a Coordinator with invalid parameters
- No cryptographic breaks required
- No privileged access required beyond normal configuration

**Attack Complexity:** Low - This is a configuration error that can occur through:
1. Misconfiguration during system setup
2. Dynamic parameter adjustment without proper validation
3. Loading saved state with inconsistent parameters

**Economic Feasibility:** No economic cost - this is a configuration issue.

**Detection Risk:** The misconfiguration may not be detected until DKG is initiated. Error logging occurs but doesn't prevent the invalid state: [11](#0-10) 

**Probability:** Moderate - While requiring misconfiguration, the lack of validation at the Coordinator level makes this easy to trigger accidentally. The asymmetry with Signer validation increases likelihood since operators may assume validation happens consistently.

### Recommendation

**Proposed Fix:** Add validation to `Config::new()` and `Config::with_timeouts()`:

```rust
impl Config {
    pub fn new(
        num_signers: u32,
        num_keys: u32,
        threshold: u32,
        message_private_key: Scalar,
    ) -> Result<Self, ConfigError> {
        // Validate num_signers <= num_keys
        if num_signers > num_keys {
            return Err(ConfigError::InsufficientKeys);
        }
        
        // Validate threshold bounds
        if threshold == 0 || threshold > num_keys {
            return Err(ConfigError::InvalidThreshold);
        }
        
        Ok(Config {
            num_signers,
            num_keys,
            threshold,
            dkg_threshold: num_keys,
            // ... rest of fields
        })
    }
}
```

Apply similar validation to `Config::with_timeouts()` to ensure `dkg_threshold >= threshold` and `dkg_threshold <= num_keys`.

**Alternative Mitigation:** If changing the return type is not feasible, add validation in `Coordinator::new()` that panics or logs a critical error for invalid configurations.

**Testing Recommendations:**
1. Add test cases attempting to create Coordinators with `num_signers > num_keys`
2. Verify rejection at Config construction time
3. Test boundary cases: `num_signers == num_keys`, `num_signers == num_keys + 1`
4. Verify PublicKeys validation catches inconsistencies

**Deployment Considerations:** This is a breaking API change if Config methods return `Result`. Consider:
1. Phased rollout with deprecation warnings
2. Backward compatibility layer that logs warnings before enforcing validation
3. Migration tool to validate existing saved states

### Proof of Concept

**Exploitation Steps:**

1. Create invalid Config:
```rust
let config = Config::new(
    10,  // num_signers
    5,   // num_keys - LESS than num_signers!
    3,   // threshold
    Scalar::random(&mut rng)
);

let coordinator = FireCoordinator::new(config);
```

2. Create PublicKeys with only 5 signers (matching available keys):
```rust
let mut public_keys = PublicKeys::default();
for i in 0..5 {
    public_keys.signers.insert(i, generate_public_key());
    public_keys.signer_key_ids.insert(i, HashSet::from([i+1]));
}
coordinator.config.public_keys = public_keys;
```

3. Start DKG:
```rust
let packet = coordinator.start_dkg_round(None).unwrap();
// dkg_wait_signer_ids now contains {0,1,2,3,4,5,6,7,8,9}
```

4. Send responses from available signers (0-4):
```rust
for i in 0..5 {
    let response = create_dkg_public_shares(i);
    coordinator.process(&response).unwrap();
    // dkg_wait_signer_ids reduces to {5,6,7,8,9}
}
```

**Expected Behavior:** Coordinator should reject the invalid configuration at construction time.

**Actual Behavior:** 
- Without timeout: Coordinator waits indefinitely for signers 5-9
- With timeout: Coordinator may timeout and fail DKG if threshold > 5
- `dkg_wait_signer_ids.is_empty()` is never true, blocking state transition

**Reproduction:** Use the test setup framework but modify to allow `num_signers > num_keys`: [12](#0-11) 

Change line 580 to use mismatched values and observe the deadlock behavior.

### Citations

**File:** src/state_machine/coordinator/fire.rs (L78-99)
```rust
                if let Some(start) = self.dkg_public_start {
                    if let Some(timeout) = self.config.dkg_public_timeout {
                        if now.duration_since(start) > timeout {
                            // check dkg_threshold to determine if we can continue
                            let dkg_size = self.compute_dkg_public_size()?;

                            if self.config.dkg_threshold > dkg_size {
                                error!("Timeout gathering DkgPublicShares for dkg round {} signing round {} iteration {}, dkg_threshold not met ({dkg_size}/{}), unable to continue", self.current_dkg_id, self.current_sign_id, self.current_sign_iter_id, self.config.dkg_threshold);
                                let wait = self.dkg_wait_signer_ids.iter().copied().collect();
                                return Ok((
                                    None,
                                    Some(OperationResult::DkgError(DkgError::DkgPublicTimeout(
                                        wait,
                                    ))),
                                ));
                            } else {
                                // we hit the timeout but met the threshold, continue
                                warn!("Timeout gathering DkgPublicShares for dkg round {} signing round {} iteration {}, dkg_threshold was met ({dkg_size}/{}), ", self.current_dkg_id, self.current_sign_id, self.current_sign_iter_id, self.config.dkg_threshold);
                                self.public_shares_gathered()?;
                                let packet = self.start_private_shares()?;
                                return Ok((Some(packet), None));
                            }
```

**File:** src/state_machine/coordinator/fire.rs (L399-399)
```rust
        self.dkg_wait_signer_ids = (0..self.config.num_signers).collect();
```

**File:** src/state_machine/coordinator/fire.rs (L486-491)
```rust
            // check that the signer_id exists in the config
            let signer_public_keys = &self.config.public_keys.signers;
            if !signer_public_keys.contains_key(&dkg_public_shares.signer_id) {
                warn!(signer_id = %dkg_public_shares.signer_id, "No public key in config");
                return Ok(());
            };
```

**File:** src/state_machine/coordinator/fire.rs (L514-516)
```rust
        if self.dkg_wait_signer_ids.is_empty() {
            self.public_shares_gathered()?;
        }
```

**File:** src/state_machine/coordinator/fire.rs (L1200-1221)
```rust
    fn compute_num_key_ids<'a, I>(&self, signer_ids: I) -> Result<u32, Error>
    where
        I: Iterator<Item = &'a u32>,
    {
        signer_ids
            .map(
                |signer_id| match self.config.public_keys.signer_key_ids.get(signer_id) {
                    Some(key_ids) => key_ids.len(),
                    None => {
                        error!("No key_ids for signer {signer_id}");
                        0usize
                    }
                },
            )
            .sum::<usize>()
            .try_into()
            .map_err(Error::TryFromInt)
    }

    fn compute_dkg_public_size(&self) -> Result<u32, Error> {
        self.compute_num_key_ids(self.dkg_public_shares.keys())
    }
```

**File:** src/state_machine/coordinator/fire.rs (L1279-1307)
```rust
    fn new(config: Config) -> Self {
        Self {
            aggregator: Aggregator::new(config.num_keys, config.threshold),
            config,
            current_dkg_id: 0,
            current_sign_id: 0,
            current_sign_iter_id: 0,
            dkg_public_shares: Default::default(),
            dkg_private_shares: Default::default(),
            dkg_end_messages: Default::default(),
            party_polynomials: Default::default(),
            message_nonces: Default::default(),
            signature_shares: Default::default(),
            aggregate_public_key: None,
            signature: None,
            schnorr_proof: None,
            message: Default::default(),
            dkg_wait_signer_ids: Default::default(),
            state: State::Idle,
            dkg_public_start: None,
            dkg_private_start: None,
            dkg_end_start: None,
            nonce_start: None,
            sign_start: None,
            malicious_signer_ids: Default::default(),
            malicious_dkg_signer_ids: Default::default(),
            coordinator_public_key: None,
        }
    }
```

**File:** src/state_machine/coordinator/frost.rs (L803-824)
```rust
    fn new(config: Config) -> Self {
        Self {
            aggregator: Aggregator::new(config.num_keys, config.threshold),
            config,
            current_dkg_id: 0,
            current_sign_id: 0,
            current_sign_iter_id: 0,
            dkg_public_shares: Default::default(),
            dkg_private_shares: Default::default(),
            dkg_end_messages: Default::default(),
            party_polynomials: Default::default(),
            public_nonces: Default::default(),
            signature_shares: Default::default(),
            aggregate_public_key: None,
            signature: None,
            schnorr_proof: None,
            message: Default::default(),
            ids_to_await: Default::default(),
            state: State::Idle,
            coordinator_public_key: None,
        }
    }
```

**File:** src/state_machine/signer/mod.rs (L292-294)
```rust
        if total_signers > total_keys {
            return Err(Error::Config(ConfigError::InsufficientKeys));
        }
```

**File:** src/state_machine/coordinator/mod.rs (L180-200)
```rust
    pub fn new(
        num_signers: u32,
        num_keys: u32,
        threshold: u32,
        message_private_key: Scalar,
    ) -> Self {
        Config {
            num_signers,
            num_keys,
            threshold,
            dkg_threshold: num_keys,
            message_private_key,
            dkg_public_timeout: None,
            dkg_private_timeout: None,
            dkg_end_timeout: None,
            nonce_timeout: None,
            sign_timeout: None,
            public_keys: Default::default(),
            verify_packet_sigs: true,
        }
    }
```

**File:** src/state_machine/coordinator/mod.rs (L204-231)
```rust
    pub fn with_timeouts(
        num_signers: u32,
        num_keys: u32,
        threshold: u32,
        dkg_threshold: u32,
        message_private_key: Scalar,
        dkg_public_timeout: Option<Duration>,
        dkg_private_timeout: Option<Duration>,
        dkg_end_timeout: Option<Duration>,
        nonce_timeout: Option<Duration>,
        sign_timeout: Option<Duration>,
        public_keys: PublicKeys,
    ) -> Self {
        Config {
            num_signers,
            num_keys,
            threshold,
            dkg_threshold,
            message_private_key,
            dkg_public_timeout,
            dkg_private_timeout,
            dkg_end_timeout,
            nonce_timeout,
            sign_timeout,
            public_keys,
            verify_packet_sigs: true,
        }
    }
```

**File:** src/state_machine/coordinator/mod.rs (L580-582)
```rust
        let num_keys = num_signers * keys_per_signer;
        let threshold = (num_keys * 7) / 10;
        let dkg_threshold = (num_keys * 9) / 10;
```
