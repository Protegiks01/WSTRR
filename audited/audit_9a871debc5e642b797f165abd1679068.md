Based on my thorough analysis of the WSTS codebase, I have validated this security claim and found it to be a **valid vulnerability**.

# Audit Report

## Title
Unbounded Polynomial Vector Size in DkgPublicShares Enables Denial of Service

## Summary
The `DkgPublicShares` message structure accepts polynomial commitment vectors of arbitrary size without validation before signature verification. A malicious signer can craft messages with oversized poly vectors that cause recipients to exhaust computational resources during hash computation for signature verification, resulting in denial of service that prevents DKG completion.

## Finding Description

The vulnerability exists in the message processing flow where size validation occurs after expensive cryptographic operations:

**1. Unbounded Structure:** The `DkgPublicShares` struct contains `comms: Vec<(u32, PolyCommitment)>` where each `PolyCommitment` has `poly: Vec<Point>` with no size constraints. [1](#0-0) [2](#0-1) 

**2. Signature Verification Before Size Validation:** When packets arrive, signature verification is performed first (default configuration): [3](#0-2) [4](#0-3) 

**3. Expensive Hash Computation:** The verification process calls `msg.hash()` which iterates over every Point in every poly vector, calling `compress()` on each: [5](#0-4) [6](#0-5) 

**4. Late Size Validation:** Size validation only occurs much later in `dkg_ended()`: [7](#0-6) [8](#0-7) 

**5. No Early Validation:** Neither the coordinator's nor signer's message handlers perform size validation before storage: [9](#0-8) [10](#0-9) 

This ordering allows a malicious signer to force recipients to perform expensive cryptographic operations on oversized data before any validation occurs.

## Impact Explanation

This vulnerability maps to **Low severity** under "Any remotely-exploitable denial of service in a node" from the defined scope.

A malicious signer can send `DkgPublicShares` messages with poly vectors significantly larger than the expected threshold size (typically ~14 points). When recipients process these messages:

1. **CPU Exhaustion:** The `hash()` function must iterate over all points and perform point compression on each. Processing thousands of points instead of ~14 causes significant CPU consumption.

2. **DKG Failure:** Victims experiencing resource exhaustion cannot complete DKG in a timely manner, preventing the protocol from establishing the distributed key required for signing operations.

3. **Network-Wide Impact:** If the malicious signer is included in the DKG participant set, all coordinators and signers must process the oversized message, potentially causing widespread disruption.

For a typical configuration with threshold=14, an attacker sending even 10,000 Points represents a 700x amplification factor, causing substantial resource consumption during signature verification before any size checks occur.

## Likelihood Explanation

**Likelihood: High**

The attack requires only:
- Valid signer credentials (explicitly allowed in threat model for up to threshold-1 malicious signers)
- Basic network access to send messages
- Ability to construct and sign WSTS protocol messages

The attack complexity is low - an attacker simply constructs a `DkgPublicShares` message with oversized poly vectors, signs it with their valid private key, and sends it to other participants. No timing windows, race conditions, or cryptographic breaks are required.

The `verify_packet_sigs` configuration defaults to `true` in production, ensuring signature verification (and thus the expensive hash computation) will occur. [11](#0-10) 

Detection is possible through message size monitoring, but occurs after resource consumption has already begun.

## Recommendation

Implement early size validation before expensive cryptographic operations:

1. **Add size limits to message handlers:** Validate that `poly.len() <= threshold` immediately upon receiving `DkgPublicShares` messages, before signature verification:

```rust
// In dkg_public_share() and gather_public_shares()
for (party_id, comm) in &dkg_public_shares.comms {
    if comm.poly.len() > self.threshold as usize {
        warn!("Received oversized polynomial commitment from signer {}", signer_id);
        return Ok(vec![]);
    }
}
```

2. **Consider deserializer limits:** Implement maximum message size limits at the deserialization layer to prevent resource exhaustion before messages reach WSTS handlers.

3. **Add configuration options:** Allow operators to configure maximum acceptable poly sizes for their deployments.

## Proof of Concept

```rust
#[test]
fn test_oversized_poly_causes_excessive_hashing() {
    use std::time::Instant;
    let mut rng = create_rng();
    
    // Normal-sized poly (threshold size)
    let normal_poly: Vec<Point> = (0..14)
        .map(|_| Point::from(Scalar::random(&mut rng)))
        .collect();
    
    // Oversized poly (100x normal)
    let oversized_poly: Vec<Point> = (0..1400)
        .map(|_| Point::from(Scalar::random(&mut rng)))
        .collect();
    
    let ctx = 0u64.to_be_bytes();
    
    let normal_shares = DkgPublicShares {
        dkg_id: 0,
        signer_id: 0,
        comms: vec![(0, PolyCommitment {
            id: ID::new(&Scalar::new(), &Scalar::new(), &ctx, &mut rng),
            poly: normal_poly,
        })],
        kex_public_key: Point::from(Scalar::random(&mut rng)),
    };
    
    let oversized_shares = DkgPublicShares {
        dkg_id: 0,
        signer_id: 0,
        comms: vec![(0, PolyCommitment {
            id: ID::new(&Scalar::new(), &Scalar::new(), &ctx, &mut rng),
            poly: oversized_poly,
        })],
        kex_public_key: Point::from(Scalar::random(&mut rng)),
    };
    
    // Measure hashing time for normal message
    let start = Instant::now();
    let mut hasher = Sha256::new();
    normal_shares.hash(&mut hasher);
    let normal_duration = start.elapsed();
    
    // Measure hashing time for oversized message
    let start = Instant::now();
    let mut hasher = Sha256::new();
    oversized_shares.hash(&mut hasher);
    let oversized_duration = start.elapsed();
    
    // Oversized message should take significantly more time
    println!("Normal message hashing: {:?}", normal_duration);
    println!("Oversized message hashing: {:?}", oversized_duration);
    assert!(oversized_duration > normal_duration * 50, 
        "Oversized message should cause substantially more computation");
}
```

### Citations

**File:** src/net.rs (L33-45)
```rust
    fn verify(&self, signature: &[u8], public_key: &ecdsa::PublicKey) -> bool {
        let mut hasher = Sha256::new();

        self.hash(&mut hasher);

        let hash = hasher.finalize();
        let sig = match ecdsa::Signature::try_from(signature) {
            Ok(sig) => sig,
            Err(_) => return false,
        };

        sig.verify(hash.as_slice(), public_key)
    }
```

**File:** src/net.rs (L139-150)
```rust
#[derive(Clone, Serialize, Deserialize, Debug, PartialEq)]
/// DKG public shares message from signer to all signers and coordinator
pub struct DkgPublicShares {
    /// DKG round ID
    pub dkg_id: u64,
    /// Signer ID
    pub signer_id: u32,
    /// List of (party_id, commitment)
    pub comms: Vec<(u32, PolyCommitment)>,
    /// Ephemeral public key for key exchange
    pub kex_public_key: Point,
}
```

**File:** src/net.rs (L152-163)
```rust
impl Signable for DkgPublicShares {
    fn hash(&self, hasher: &mut Sha256) {
        hasher.update("DKG_PUBLIC_SHARES".as_bytes());
        hasher.update(self.dkg_id.to_be_bytes());
        hasher.update(self.signer_id.to_be_bytes());
        for (party_id, comm) in &self.comms {
            hasher.update(party_id.to_be_bytes());
            for a in &comm.poly {
                hasher.update(a.compress().as_bytes());
            }
        }
    }
```

**File:** src/common.rs (L26-33)
```rust
#[derive(Clone, Debug, Deserialize, Serialize, PartialEq)]
/// A commitment to a polynonial, with a Schnorr proof of ownership bound to the ID
pub struct PolyCommitment {
    /// The party ID with a schnorr proof
    pub id: ID,
    /// The public polynomial which commits to the secret polynomial
    pub poly: Vec<Point>,
}
```

**File:** src/common.rs (L319-321)
```rust
pub fn check_public_shares(poly_comm: &PolyCommitment, threshold: usize, ctx: &[u8]) -> bool {
    poly_comm.verify(ctx) && poly_comm.poly.len() == threshold
}
```

**File:** src/state_machine/signer/mod.rs (L463-470)
```rust
        if self.verify_packet_sigs {
            let Some(coordinator_public_key) = self.coordinator_public_key else {
                return Err(Error::MissingCoordinatorPublicKey);
            };
            if !packet.verify(&self.public_keys, &coordinator_public_key) {
                return Err(Error::InvalidPacketSignature);
            }
        }
```

**File:** src/state_machine/signer/mod.rs (L551-562)
```rust
        for signer_id in &signer_ids_set {
            if let Some(shares) = self.dkg_public_shares.get(signer_id) {
                if shares.comms.is_empty() {
                    missing_public_shares.insert(*signer_id);
                } else {
                    for (party_id, comm) in shares.comms.iter() {
                        if !check_public_shares(comm, threshold, &self.dkg_id.to_be_bytes()) {
                            bad_public_shares.insert(*signer_id);
                        } else {
                            self.commitments.insert(*party_id, comm.clone());
                        }
                    }
```

**File:** src/state_machine/signer/mod.rs (L974-1026)
```rust
    pub fn dkg_public_share(
        &mut self,
        dkg_public_shares: &DkgPublicShares,
    ) -> Result<Vec<Message>, Error> {
        debug!(
            "received DkgPublicShares from signer {} {}/{}",
            dkg_public_shares.signer_id,
            self.commitments.len(),
            self.signer.get_num_parties(),
        );

        let signer_id = dkg_public_shares.signer_id;

        // check that the signer_id exists in the config
        let Some(_signer_public_key) = self.public_keys.signers.get(&signer_id) else {
            warn!(%signer_id, "No public key configured");
            return Ok(vec![]);
        };

        for (party_id, _) in &dkg_public_shares.comms {
            if !SignerType::validate_party_id(
                signer_id,
                *party_id,
                &self.public_keys.signer_key_ids,
            ) {
                warn!(%signer_id, %party_id, "signer sent polynomial commitment for wrong party");
                return Ok(vec![]);
            }
        }

        let have_shares = self
            .dkg_public_shares
            .contains_key(&dkg_public_shares.signer_id);

        if have_shares {
            info!(signer_id = %dkg_public_shares.signer_id, "received duplicate DkgPublicShares");
            return Ok(vec![]);
        }

        let Some(signer_key_ids) = self.public_keys.signer_key_ids.get(&signer_id) else {
            warn!(%signer_id, "No key_ids configured");
            return Ok(vec![]);
        };

        for key_id in signer_key_ids {
            self.kex_public_keys
                .insert(*key_id, dkg_public_shares.kex_public_key);
        }

        self.dkg_public_shares
            .insert(dkg_public_shares.signer_id, dkg_public_shares.clone());
        Ok(vec![])
    }
```

**File:** src/state_machine/coordinator/fire.rs (L218-225)
```rust
        if self.config.verify_packet_sigs {
            let Some(coordinator_public_key) = self.coordinator_public_key else {
                return Err(Error::MissingCoordinatorPublicKey);
            };
            if !packet.verify(&self.config.public_keys, &coordinator_public_key) {
                return Err(Error::InvalidPacketSignature);
            }
        }
```

**File:** src/state_machine/coordinator/fire.rs (L477-518)
```rust
    fn gather_public_shares(&mut self, packet: &Packet) -> Result<(), Error> {
        if let Message::DkgPublicShares(dkg_public_shares) = &packet.msg {
            if dkg_public_shares.dkg_id != self.current_dkg_id {
                return Err(Error::BadDkgId(
                    dkg_public_shares.dkg_id,
                    self.current_dkg_id,
                ));
            }

            // check that the signer_id exists in the config
            let signer_public_keys = &self.config.public_keys.signers;
            if !signer_public_keys.contains_key(&dkg_public_shares.signer_id) {
                warn!(signer_id = %dkg_public_shares.signer_id, "No public key in config");
                return Ok(());
            };

            let have_shares = self
                .dkg_public_shares
                .contains_key(&dkg_public_shares.signer_id);

            if have_shares {
                info!(signer_id = %dkg_public_shares.signer_id, "received duplicate DkgPublicShares");
                return Ok(());
            }

            self.dkg_wait_signer_ids
                .remove(&dkg_public_shares.signer_id);

            self.dkg_public_shares
                .insert(dkg_public_shares.signer_id, dkg_public_shares.clone());
            debug!(
                dkg_id = %dkg_public_shares.dkg_id,
                signer_id = %dkg_public_shares.signer_id,
                "DkgPublicShares received"
            );
        }

        if self.dkg_wait_signer_ids.is_empty() {
            self.public_shares_gathered()?;
        }
        Ok(())
    }
```

**File:** src/state_machine/coordinator/mod.rs (L194-198)
```rust
            dkg_end_timeout: None,
            nonce_timeout: None,
            sign_timeout: None,
            public_keys: Default::default(),
            verify_packet_sigs: true,
```
