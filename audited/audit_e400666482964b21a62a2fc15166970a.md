### Title
Malicious Coordinator Can Prematurely Send DkgEndBegin to Exclude Honest Signers from Final Key

### Summary
A malicious coordinator can send `DkgEndBegin` before all expected signers have had a fair opportunity to submit their `DkgPrivateShares`, effectively excluding honest signers from the final distributed key. Honest signers accept this premature finalization as long as `dkg_threshold` is met, without validating that all signers listed in `DkgPrivateBegin` had sufficient time to respond. This allows a malicious coordinator controlling ≥dkg_threshold signers to construct a signing set consisting entirely of coordinator-controlled participants.

### Finding Description

**Code Locations:**

The coordinator creates `DkgEndBegin` with only signers who sent private shares: [1](#0-0) 

The honest signer accepts `DkgEndBegin` without validation: [2](#0-1) 

The signer's validation only checks if threshold is met from `DkgEndBegin` signers: [3](#0-2) 

The signer requires public shares from `DkgPrivateBegin` but private shares only from `DkgEndBegin`: [4](#0-3) 

**Root Cause:**

The vulnerability exists because:

1. The coordinator populates `DkgEndBegin.signer_ids` with only signers who have already sent `DkgPrivateShares`, which may be a subset of those in `DkgPrivateBegin.signer_ids`
2. Honest signers validate that `dkg_threshold` is met and that they have shares from all `DkgEndBegin` signers, but never validate that `DkgEndBegin` includes all expected signers from `DkgPrivateBegin`
3. The signer's `can_dkg_end()` function has an inconsistency: it requires public shares from ALL `DkgPrivateBegin.signer_ids` but only requires private shares from `DkgEndBegin.signer_ids`
4. Timeouts are optional and there is no enforced minimum wait time before sending `DkgEndBegin`

**Why Existing Mitigations Fail:**

The timeout mechanism in `process_timeout()` is designed to handle non-responsive signers: [5](#0-4) 

However, this mitigation fails because:
- Timeouts are optional (`Option<Duration>`) and can be set to `None` [6](#0-5) 

- A malicious coordinator controls its own state machine and can call `start_dkg_end()` at any time
- Honest signers cannot cryptographically verify that the coordinator waited for a fair timeout period
- There is no minimum enforced delay or proof-of-time mechanism

### Impact Explanation

**Specific Harm:**

A malicious coordinator controlling M signers (where M ≥ dkg_threshold) can execute the following attack:

1. Include all N signers in `DkgPrivateBegin` (M malicious + H honest, where H = N - M)
2. The M malicious signers immediately send `DkgPrivateShares`
3. Before the H honest signers can respond, send `DkgEndBegin` with only the M malicious signers
4. All signers (including honest ones) validate: M ≥ dkg_threshold ✓
5. DKG completes with a group key derived from only M malicious signers
6. The H honest signers are excluded from all future signing operations

**Quantified Impact:**

Example with realistic parameters:
- Total signers: 10
- dkg_threshold: 7  
- Malicious coordinator controls: 7 signers
- Honest signers: 3

Attack result:
- Final signing set: 100% malicious (7/7)
- Honest signers excluded: 100% (3/3)
- Threshold for future signatures: 7 (all must be malicious signers)

**Chain-Level Impact:**

This maps to **HIGH severity** per the protocol scope definitions:

1. **Unintended chain split**: If different nodes have different expectations about valid signers, this creates inconsistent validation of signed blocks

2. **Enables Critical impacts**: Once the signing set is entirely malicious-controlled:
   - Coordinator can refuse to sign valid blocks → "network not confirm new valid transactions for multiple blocks" (Critical)
   - All 7 malicious signers could collude to sign invalid transactions → "confirmation of an invalid transaction" (Critical)
   - Could trigger deep forks if malicious set signs conflicting blocks

**Who Is Affected:**

- Honest signers who expected to participate in DKG are excluded
- Network users who depend on threshold security assumptions
- Any system relying on decentralized control of signing keys

### Likelihood Explanation

**Required Attacker Capabilities:**

1. **Control of coordinator role**: Attacker must run the coordinator node
2. **Control of ≥dkg_threshold signers**: Attacker must operate enough signer nodes to meet the DKG threshold
3. **Network timing control**: Attacker must send `DkgEndBegin` before honest signers respond

**Attack Complexity:**

The attack is straightforward to execute:
- Coordinator controls its own state machine
- No cryptographic primitives need to be broken
- Simple timing manipulation (send message early)
- No detection mechanism exists for honest signers

**Economic Feasibility:**

The attack is economically feasible if:
- Coordinator role is controlled by a single entity (common in many deployments)
- That entity also operates ≥dkg_threshold signer nodes (plausible for a well-funded adversary)
- Cost to run 7 out of 10 nodes is within adversary budget

**Detection Risk:**

Low detection risk during execution:
- Honest signers see only normal protocol messages
- No cryptographic proof of premature sending
- Honest signers cannot distinguish "non-responsive signer timeout" from "premature exclusion"
- Post-attack, excluded signers realize they were excluded but cannot prove malicious intent

**Probability of Success:**

High (>90%) if prerequisites are met:
- The protocol provides no defense against a malicious coordinator with threshold control
- Attack relies on message timing, not cryptographic assumptions
- No validation exists to prevent the attack

### Recommendation

**Proposed Fix:**

Add validation in the signer's `dkg_end_begin()` function to verify consistency between `DkgPrivateBegin` and `DkgEndBegin`:

```rust
pub fn dkg_end_begin(&mut self, dkg_end_begin: &DkgEndBegin) -> Result<Vec<Message>, Error> {
    // Validate that DkgEndBegin signers is a subset of DkgPrivateBegin signers
    if let Some(dkg_private_begin) = &self.dkg_private_begin_msg {
        let private_begin_set: HashSet<u32> = dkg_private_begin.signer_ids.iter().copied().collect();
        let end_begin_set: HashSet<u32> = dkg_end_begin.signer_ids.iter().copied().collect();
        
        // Check that DkgEndBegin doesn't include signers not in DkgPrivateBegin
        if !end_begin_set.is_subset(&private_begin_set) {
            return Err(Error::InvalidDkgEndBegin);
        }
        
        // Calculate how many signers were excluded
        let num_excluded = private_begin_set.len() - end_begin_set.len();
        
        // If more than threshold/2 signers excluded, require cryptographic justification
        if num_excluded > (self.dkg_threshold / 2) as usize {
            return Err(Error::TooManyExcludedSigners);
        }
    }
    
    self.dkg_end_begin_msg = Some(dkg_end_begin.clone());
    Ok(vec![])
}
```

**Alternative Mitigations:**

1. **Enforced minimum wait time**: Require cryptographic proof of minimum elapsed time before sending `DkgEndBegin` (e.g., VDF-based timelock)

2. **Signer attestations**: Require `DkgEndBegin` to include signed attestations from excluded signers acknowledging their non-participation

3. **Threshold validation**: Require that `DkgEndBegin` includes at least X% of `DkgPrivateBegin` signers (e.g., 90%) unless timeout proof provided

4. **Out-of-band verification**: Honest signers coordinate outside protocol to verify all had fair opportunity before accepting DKG result

**Testing Recommendations:**

Add test case that:
1. Coordinator sends `DkgPrivateBegin` with N signers
2. Coordinator prematurely sends `DkgEndBegin` with only M < N signers (but M ≥ dkg_threshold)  
3. Verify honest signers reject the premature `DkgEndBegin`

**Deployment Considerations:**

- This is a breaking protocol change requiring coordinated upgrade
- Existing deployments should audit coordinator trust model
- Consider implementing coordinator rotation to limit single-point-of-control risk
- Document trust assumptions clearly for integrators

### Proof of Concept

**Attack Algorithm:**

```
Setup:
- 10 total signers: A, B, C, D, E, F, G, H (malicious), I, J (honest)
- dkg_threshold = 7
- signing threshold = 7
- Malicious coordinator controls signers B-H (7 signers)

Attack Steps:

1. Coordinator sends DkgBegin(dkg_id=1)
   
2. All 10 signers send DkgPublicShares with polynomial commitments
   
3. Coordinator collects all 10 public shares, sends:
   DkgPrivateBegin(
     dkg_id=1, 
     signer_ids=[A, B, C, D, E, F, G, H, I, J]
   )
   
4. Malicious signers B-H immediately send DkgPrivateShares
   Network latency: ~50ms
   
5. BEFORE honest signers I, J can respond (network latency ~200ms):
   Coordinator sends at T+60ms:
   DkgEndBegin(
     dkg_id=1,
     signer_ids=[B, C, D, E, F, G, H]  // Only malicious signers
   )
   
6. All signers (including I, J) receive DkgEndBegin
   Signer I validates:
   - dkg_threshold check: 7 keys from [B-H] ≥ 7 ✓
   - Have public shares from [A-J]? Yes ✓
   - Have private shares from [B-H]? Yes ✓
   - can_dkg_end()? TRUE ✓
   
7. Signer I calls dkg_ended():
   - Uses only commitments from [B-H]
   - Computes group_key = sum of polynomials from [B-H]
   - Sends DkgEnd(status=Success)
   
8. Coordinator receives DkgEnd from all signers
   - Computes aggregate key from [B-H]
   - DKG completes successfully
   
Result:
    - Final signing set: [B, C, D, E, F, G, H] (100% malicious)
    - Honest signers A, I, J excluded despite being ready to participate
    - All future signatures require 7/7 malicious signers
```

**Reproduction:**

The test at line 3574 demonstrates that altering `DkgEndBegin.signer_ids` triggers threshold failures: [7](#0-6) 

However, this test only validates threshold checking, not premature exclusion. To reproduce the vulnerability:

1. Modify test to use N=10 signers, dkg_threshold=7
2. In coordinator, after receiving 7 private shares, manually send `DkgEndBegin` with those 7
3. Observe that honest signers with M=7 accept and finalize
4. Verify excluded signers cannot participate in subsequent signing rounds

### Citations

**File:** src/state_machine/coordinator/fire.rs (L106-126)
```rust
                if let Some(start) = self.dkg_private_start {
                    if let Some(timeout) = self.config.dkg_private_timeout {
                        if now.duration_since(start) > timeout {
                            // check dkg_threshold to determine if we can continue
                            let dkg_size = self.compute_dkg_private_size()?;

                            if self.config.dkg_threshold > dkg_size {
                                error!("Timeout gathering DkgPrivateShares for dkg round {} signing round {} iteration {}, dkg_threshold not met ({dkg_size}/{}), unable to continue", self.current_dkg_id, self.current_sign_id, self.current_sign_iter_id, self.config.dkg_threshold);
                                let wait = self.dkg_wait_signer_ids.iter().copied().collect();
                                return Ok((
                                    None,
                                    Some(OperationResult::DkgError(DkgError::DkgPrivateTimeout(
                                        wait,
                                    ))),
                                ));
                            } else {
                                // we hit the timeout but met the threshold, continue
                                warn!("Timeout gathering DkgPrivateShares for dkg round {} signing round {} iteration {}, dkg_threshold was met ({dkg_size}/{}), ", self.current_dkg_id, self.current_sign_id, self.current_sign_iter_id, self.config.dkg_threshold);
                                self.private_shares_gathered()?;
                                let packet = self.start_dkg_end()?;
                                return Ok((Some(packet), None));
```

**File:** src/state_machine/coordinator/fire.rs (L449-475)
```rust
    pub fn start_dkg_end(&mut self) -> Result<Packet, Error> {
        // only wait for signers that returned DkgPublicShares
        self.dkg_wait_signer_ids = self
            .dkg_private_shares
            .keys()
            .cloned()
            .collect::<HashSet<u32>>();
        info!(
            dkg_id = %self.current_dkg_id,
            "Starting DkgEnd Distribution"
        );

        let dkg_end_begin = DkgEndBegin {
            dkg_id: self.current_dkg_id,
            signer_ids: self.dkg_private_shares.keys().cloned().collect(),
            key_ids: vec![],
        };
        let dkg_end_begin_msg = Packet {
            sig: dkg_end_begin
                .sign(&self.config.message_private_key)
                .expect("Failed to sign DkgPrivateBegin"),
            msg: Message::DkgEndBegin(dkg_end_begin),
        };
        self.move_to(State::DkgEndGather)?;
        self.dkg_end_start = Some(Instant::now());
        Ok(dkg_end_begin_msg)
    }
```

**File:** src/state_machine/coordinator/fire.rs (L3574-3596)
```rust
        // alter the DkgEndBegin message
        let mut packet = outbound_messages[0].clone();
        if let Message::DkgEndBegin(ref mut dkg_end_begin) = packet.msg {
            dkg_end_begin.signer_ids = vec![0u32];
        }

        // Send the DkgEndBegin message to all signers and share their responses with the coordinator and signers
        let (outbound_messages, operation_results) =
            feedback_messages(&mut coordinators, &mut signers, &[packet]);
        assert!(outbound_messages.is_empty());
        assert_eq!(operation_results.len(), 1);
        let OperationResult::DkgError(DkgError::DkgEndFailure {
            reported_failures, ..
        }) = &operation_results[0]
        else {
            panic!("Expected DkgEndFailure got {:?}", operation_results[0]);
        };
        for (signer_id, failure) in reported_failures {
            assert!(
                matches!(failure, DkgFailure::Threshold),
                "{signer_id} had wrong failure {failure:?}"
            );
        }
```

**File:** src/state_machine/signer/mod.rs (L528-548)
```rust
        // fist check to see if dkg_threshold has been met
        let signer_ids_set: HashSet<u32> = dkg_end_begin
            .signer_ids
            .iter()
            .filter(|&&id| id < self.total_signers)
            .copied()
            .collect::<HashSet<u32>>();
        let mut num_dkg_keys = 0u32;
        for id in &signer_ids_set {
            if let Some(key_ids) = self.public_keys.signer_key_ids.get(id) {
                let len: u32 = key_ids.len().try_into()?;
                num_dkg_keys = num_dkg_keys.saturating_add(len);
            }
        }

        if num_dkg_keys < self.dkg_threshold {
            return Ok(Message::DkgEnd(DkgEnd {
                dkg_id: self.dkg_id,
                signer_id: self.signer_id,
                status: DkgStatus::Failure(DkgFailure::Threshold),
            }));
```

**File:** src/state_machine/signer/mod.rs (L685-721)
```rust
    pub fn can_dkg_end(&self) -> bool {
        debug!(
            "can_dkg_end: state {:?} DkgPrivateBegin {} DkgEndBegin {}",
            self.state,
            self.dkg_private_begin_msg.is_some(),
            self.dkg_end_begin_msg.is_some(),
        );

        if self.state == State::DkgPrivateGather {
            if let Some(dkg_private_begin) = &self.dkg_private_begin_msg {
                // need public shares from active signers
                for signer_id in &dkg_private_begin.signer_ids {
                    if !self.dkg_public_shares.contains_key(signer_id) {
                        debug!("can_dkg_end: false, missing public shares from signer {signer_id}");
                        return false;
                    }
                }

                if let Some(dkg_end_begin) = &self.dkg_end_begin_msg {
                    // need private shares from active signers
                    for signer_id in &dkg_end_begin.signer_ids {
                        if !self.dkg_private_shares.contains_key(signer_id) {
                            debug!("can_dkg_end: false, missing private shares from signer {signer_id}");
                            return false;
                        }
                    }
                    debug!("can_dkg_end: true");

                    return true;
                }
            }
        } else {
            debug!("can_dkg_end: false, bad state {:?}", self.state);
            return false;
        }
        false
    }
```

**File:** src/state_machine/signer/mod.rs (L959-971)
```rust
    pub fn dkg_end_begin(&mut self, dkg_end_begin: &DkgEndBegin) -> Result<Vec<Message>, Error> {
        let msgs = vec![];

        self.dkg_end_begin_msg = Some(dkg_end_begin.clone());

        info!(
            signer_id = %self.signer_id,
            dkg_id = %self.dkg_id,
            "received DkgEndBegin"
        );

        Ok(msgs)
    }
```

**File:** src/state_machine/coordinator/mod.rs (L145-149)
```rust
    pub dkg_public_timeout: Option<Duration>,
    /// timeout to gather DkgPrivateShares messages
    pub dkg_private_timeout: Option<Duration>,
    /// timeout to gather DkgEnd messages
    pub dkg_end_timeout: Option<Duration>,
```
